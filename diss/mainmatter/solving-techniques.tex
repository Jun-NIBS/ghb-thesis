% Copyright (c) 2017, Gabriel Hjort Blindell <ghb@kth.se>
%
% This work is licensed under a Creative Commons 4.0 International License (see
% LICENSE file or visit <http://creativecommons.org/licenses/by/4.0/> for a copy
% of the license).

\chapter{Solving Techniques}
\labelChapter{solving-techniques}

\todo{write chapter overview}

\todo{state clearly Mats' contribution}


\section{Refined Objective Function}
\labelSection{st-refined-objective-function}

As stated in \refChapter{constraint-model},
\refEquation{naive-objective-function} is a naive implementation of the
\gls{objective function} that offers poor \gls{propagation}.
%
This is because it fails to reason on how cost is distributed across the
\glspl{operation} that need to be covered.
%
\begin{figure}
  \mbox{}%
  \hfill%
  \subcaptionbox{UF graph\labelFigure{cost-example-graph}}%
                {%
                  \input{figures/solving-techniques/cost-example-graph}%
                }%
  \hfill%
  \subcaptionbox{Cost matrix\labelFigure{cost-example-matrix}}%
                {%
                  \figureFontSize%
                  \begin{minipage}{50mm}%
                    \centering%
                    \begin{displaymath}
                      \begin{adjblockarray}{cccccc}{1ex}
                          \text{\tabhead op}
                        & \text{\tabhead match}
                        & \text{\tabhead block}
                        & \multicolumn{3}{c}{%
                            \text{%
                              \parbox{20.5mm}{%
                                % The parbox is used to create a bit of space
                                % between the content and the right bracket
                                \centering\tabhead opcost%
                              }%
                            }%
                          } \\[-.5ex]
                        \begin{block}{[cccc@{\;\times\;}c@{\;=\;}c]}
                          \rule{0pt}{2.5ex}
                          o_1 & m_1 & b_1 & 4 & 10 & 40 \\
                          o_1 & m_1 & b_2 & 4 &  1 &  4 \\
                          o_1 & m_3 & b_1 & 3 & 10 & 30 \\
                          o_1 & m_3 & b_2 & 3 &  1 &  3 \\
                          o_2 & m_2 & b_1 & 1 & 10 & 10 \\
                          o_2 & m_2 & b_2 & 1 &  1 &  1 \\
                          o_2 & m_3 & b_1 & 2 & 10 & 20 \\
                          o_2 & m_3 & b_2 & 2 &  1 &  2 \\[.55ex]
                        \end{block}
                      \end{adjblockarray}
                    \end{displaymath}
                  \end{minipage}%
                }%
  \hfill%
  \mbox{}

  \caption[Example illustrating match cost distributed over operations]%
          {%
            Example illustrating match cost distributed over operations.
            %
            It is assumed that matches~$m_1$, $m_2$, and~$m_3$ have costs~4,
            1, and~5, respectively, and that they can be placed in one of two
            blocks, $b_1$ and $b_2$, with execution frequencies~10 and~1,
            respectively.
            %
            The cost of $m_3$ distributed over $o_1$ and $o_2$ is~3 and~2,
            respectively%
          }
  \labelFigure{cost-example}
\end{figure}
%
See for example \refFigure{cost-example}.
%
Assume a \gls{UF graph} that can be covered by three \glspl{match} -- $m_1$,
$m_2$, and~$m_3$ -- which have costs~4, 1, and~5, respectively, and that they
can be placed in one of two blocks, $b_1$ and $b_2$, with execution
frequencies~10 and~1, respectively (\refFigure{cost-example-graph}).
%
Because \refEquation{naive-objective-function} is modeled as a summation, it can
only propagate the bounds of the \gls{cost variable}.
%
Consequently, for any \glspl{match} where their $\mVar{sel}$~\gls{variable} have
yet to be decided, either all those \glspl{match} are selected and placed in the
\gls{block} with highest execution frequency, or none are selected.
%
In the example above, this means the \gls{cost variable} is initially bounded as
\mbox{$0 < \mVar{cost} < 100$}, which are very weak bounds as we know that the
\gls{UF graph} must at least be covered at a cost of~5 (either both $m_1$ and
$m_2$ are selected and placed in $b_2$, or $m_3$ is selected and placed in
$b_2$) and can at most be covered at a cost of~50 (the selected \glspl{match}
are placed in $b_1$).

Instead of reasoning about the cost incurred by the \glspl{match} -- which may
or may not be selected -- a better approach is to infer the cost incurred on the
\glspl{operation} since these must always be covered.
%
The idea is as follows.
%
First, for each \gls{match}~$m$, evenly divide the cost of $m$ over each
\gls{operation}~$o$ covered by $m$.
%
Let \mbox{$\mOpCost(m, o) \in \mNatNumSet$} denote this cost such that
\mbox{$\sum_{o \in \mCovers(m)} \mOpCost(m, o) = \mCost(m)$} holds for every
\gls{match}~$m$.\!%
%
\footnote{%
  \setlength{\abovedisplayskip}{1ex}%
  \setlength{\belowdisplayskip}{1ex}%
  %
  If a strict partial order $<$ exists over the set of \glspl{operation}, and
  $\mCovers(m)$ returns an ordered, 1-indexed list for which \mbox{$o_1 < o_2 <
    \cdots < o_k$} holds, then the cost can be divided as follows.
  %
  Given a match~$m$, let \mbox{$q = \lfloor \mCost(m) / \mCard{\!\mCovers(m)}
    \rfloor$} and \mbox{$r = \mCost(m) \! \mod \mCard{\!\mCovers(m)}$}.
  %
  Then
  %
  \begin{displaymath}
    \mOpCost(m, o) =
    \left\{
    \begin{array}{ll}
      q + 1 & \text{if $o < \mCovers(m)[r+1]$}, \\
      q     & \text{otherwise}. \\
    \end{array}
    \right.
  \end{displaymath}
}
%
Then, for each \gls{block}~$b$, weigh \mbox{$\mOpCost(m, o)$} with the execution
frequency of~$b$.
%
This information can be represented as a cost matrix
%
\begin{equation}
  \begin{bmatrix}
    \begin{array}{@{\:}c|c@{\:}}
        o, m, b, \big( \mOpCost(m, o) \times \mFreq(b) \big)
      & m \in \mMatchSet, o \in \mCovers(m), b \in \mBlockSet
    \end{array}
  \end{bmatrix}
  \labelEquation{cost-matrix}
\end{equation}
where each row denotes the cost of an \gls{operation}~$o$ if covered by a
\gls{match}~$m$ and placed in a \gls{block}~$b$.
%
An example of this cost matrix is given in \refFigure{cost-example}, from which
we can deduce that the cost of covering operations~$o_1$ and~$o_2$ is between~3
and~40 respectively between~1 and~20 (\refFigure{cost-example-matrix}).
%
Hence the total cost can be bounded as \mbox{$4 < \mVar{cost} < 60$}, which is a
much tighter bound compared to that achieved using the naive \gls{objective
  function}.
%
This in turn has a tremendous impact on solving time, for reasons that will
become clear in \refSection{st-cost-bounds}.\!%
%
\footnote{%
  For the experiments in \cite{HjortBlindellEtAl:2017:CASES}, the refined
  \gls{objective function} was actually implemented as \emph{first} multiply the
  \gls{match} cost with the execution frequency, and \emph{then} evenly divide
  the product over the covered \glspl{operation}.
  %
  While this scheme also greatly reduces solving time compared to the naive
  \gls{objective function}, it proves to be significantly inferior to dividing
  the cost as in \refEquation{cost-matrix}.
  %
  One possible explanation is that it may result in weaker bounds -- for the
  example given in \refFigure{cost-example}, using this scheme bounds the total
  cost as \mbox{$4 < \mVar{cost} < 65$} -- but this does not apply for every
  case.
  %
  Hence the intuition behind why it is better to first divide the \gls{match}
  cost and then multiply the execution frequency remains unclear, thus
  underscoring the fact that seemingly trivial changes to a \gls{constraint
    model} may have considerable impact.%
}


\subsubsection{Variables}

The set of \glspl{variable} \mbox{$\mVar{ocost}[o] \in \mNatNumSet$} models the
cost incurred by covering operation~$o$\hspace{-.8pt}.
%
It is assumed the \gls{domain} is the same as for the \gls{cost variable}.


\subsubsection{Constraints}

For each \gls{operation}~$o$\hspace{-.8pt}, the combination
\mbox{$o\hspace{-.8pt}, \mVar{omatch}[o], \mVar{oplace}[o], \mVar{ocost}[o]$}
must appear as a row in the cost matrix.
%
Hence, given a cost matrix~$\mCostMatrix$ this \gls{constraint} is modeled as
%
\begin{equation}
  \mTable\left(
    o\hspace{-1pt},
    \mVar{omatch}[o],
    \mVar{oplace}[o],
    \mVar{ocost}[o],
    \mCostMatrix
  \right)\!,
  \forall o \in \mOpSet \hspace{-.8pt}.
  \labelEquation{omatch-oplace-ocost-connection}
\end{equation}
%
The total cost is then modeled as
%
\begin{equation}
  \mVar{cost} = \sum_{o \in \mOpSet} \mVar{ocost}[o].
  \labelEquation{total-cost}
\end{equation}


\section{Tightening the Cost Bounds}
\labelSection{st-cost-bounds}

As explained in \refChapter{constraint-programming}, in \gls{CP} optimization
problems are solved using \gls{branch and bound}.
%
In other words, when a \gls{solution} is found a \gls{constraint} is added to
the \glsshort{constraint model}, forcing any subsequently found \glspl{solution}
to be strictly better.
%
This means that if a part of the \gls{search space} is known not to contain any
better \glspl{solution} -- this is achieved by checking the current lower bound
of the \gls{cost variable} -- then this part need not be explored during
\gls{search}.
%
For this to be effective, however, it must be possible to infer reasonable
bounds on the \gls{cost variable}, which asserts the need for the refined
\gls{objective function} introduced in
\refSection{st-refined-objective-function}.

By the same mechanism, solving can improved by tightening the lower and upper
bounds of the \gls{cost variable} before commencing \gls{search}.
%
A tight upper bound helps the \gls{constraint solver} to prune away parts of the
\gls{search space} that contains inferior \glspl{solution}, while a tight lower
bound helps the \gls{constraint solver} to prune away parts of the \gls{search
  space} that contains no \glspl{solution}.
%
A decent upper bound can be computed by solving the same problem using a greedy
but fast heuristic.
%
To this end, any modern \gls{compiler} can be used.
%
A decent lower bound be computed by solving a relaxed version of the
\gls{constraint model} that only models the \gls{global.is} \gls{instruction
  selection} and \gls{block ordering} problems, which obviously is simpler to
solve than the complete \glsshort{constraint model}.
%
Hence, the relaxed \glsshort{constraint model} consists of only the
$\mVar{omatch}$, $\mVar{opcosts}$, $\mVar{sel}$, $\mVar{succ}$, and
$\mVar{cost}$ variables, \refEquation{operation-coverage}, relaxed versions of
Eqs.\thinspace\refEquation*{block-order} and \refEquation*{fall-through} that
allow fall-throughs via non-empty \glspl{block}, and modified versions of
Eqs.\thinspace\refEquation*{cost-matrix}--\refEquation*{total-cost} that do not
take the execution frequencies into account.

If $\mRelaxedCost$ and $\mHeuristicCost$ denote the cost computed from the
relaxation and by the heuristic, respectively, then the \gls{cost variable} is
bounded as
%
\begin{equation}
  \mRelaxedCost \leq \mVar{cost} < \mHeuristicCost.
  \labelEquation{lower-bound}
\end{equation}


\section{Branching Strategies}
\labelSection{st-branching-strategies}

\todo{mention mimicking of maximum munch}

\todo{first branch on the $\mVar{ocost}$ variables}

\todo{then branch on the block order}


\section{Implied Constraints}
\labelSection{st-impl-constraints}

\todo{mention that \refEquation{pattern-selection-using-gcc} did not give for
  our model}


\section{Symmetry and Dominance Breaking Constraints}
\labelSection{st-dom-breaking-constraints}

\todo{write intro}


\subsubsection{Location of State Nodes}

Since \glspl{datum} also includes the \glspl{state node}, this means a
$\mVar{loc}$~\gls{variable} will be allocated for each individual \gls{state
  node}.
%
However, since \glspl{state node} are abstract entities used only to capture
implicit dependencies between certain \gls{operation}, the assignment to these
\glspl{variable} has no actual bearing on the \gls{solution}, thus giving rise
to many symmetric \glspl{solution}.
%
Consequently, it makes sense to fix the location for each \gls{state node},
which is modeled as
%
\begin{equation}
  \mVar{loc}[d] = \mNullLocation,
  \forall d \in \mDataSet, \text{$d$ is a \gls{state node}}.
  \labelEquation{loc-of-state-nodes}
\end{equation}


\subsubsection{Data of Non-Selected Matches}

The $\mVar{alt}$~\glspl{variable} of \glspl{match} that are not selected still
need to be assigned a value.
%
Since this assignment does not matter for the \gls{solution}, it gives rise to
many symmetric \glspl{solution}.
%
We therefore fix the $\mVar{alt}$ assignments in such cases, which is modeled as
%
\begin{equation}
  \begin{array}{c}
    \neg\mVar{sel}[m] \mImp \mVar{alt}[p] = \min(\mDataSet[p]), \\
    \forall m \in \mMatchSet,
    \forall p \in \mDefines(m) \cup \mUses(m).
  \end{array}
  \labelEquation{operands-of-non-selected-matches}
\end{equation}


\subsubsection{Interchangeable Data}

As described in \refSection{modeling-value-reuse}, \glspl{datum} in the \gls{UF
  graph} that are copies of the same value are \gls{copy-related.d} and
therefore interchangeable.
%
\begin{figure}
  \begin{minipage}{58mm}%
    \centering%
    \subcaptionbox{%
                    UF graph, where the values \irVar{v}[1] and \irVar{v}[2]
                    constitute a chain of interchangeable data%
                    \labelFigure{interchangeable-data-example-annotated-graph}%
                  }%
                  [\textwidth]%
                  {%
                    \input{%
                      figures/solving-techniques/%
                      interchangeable-data-example-annotated-graph%
                    }%
                  }

    \vspace{\betweensubfigures}

    \subcaptionbox{%
                    Symmetries due to how data can be connected to operands.
                    %
                    We wish to forbid the second solution%
                    \labelFigure{interchangeable-data-example-alt-solutions}%
                  }%
                  [\textwidth]%
                  {%
                    \input{%
                      figures/solving-techniques/%
                      interchangeable-data-example-alt-1%
                    }%
                    \hspace{8mm}%
                    \input{%
                      figures/solving-techniques/%
                      interchangeable-data-example-alt-2%
                    }%
                  }%
  \end{minipage}%
  \hfill%
  \begin{minipage}{58mm}%
    \centering%
    \subcaptionbox{%
                    Symmetries due to how null-copy matches can be selected.
                    %
                    We wish to forbid the second solution%
                    \labelFigure{interchangeable-data-example-null-solutions}%
                  }%
                  [\textwidth]%
                  {%
                    \input{%
                      figures/solving-techniques/%
                      interchangeable-data-example-null-1%
                    }%
                    \hspace{8mm}%
                    \input{%
                      figures/solving-techniques/%
                      interchangeable-data-example-null-2%
                    }%
                  }

    \vspace{\betweensubfigures}

    \subcaptionbox{%
                    Symmetries due to how kill matches can be selected.
                    %
                    We wish to forbid the second solution%
                    \labelFigure{interchangeable-data-example-kill-solutions}%
                  }%
                  [\textwidth]%
                  {%
                    \input{%
                      figures/solving-techniques/%
                      interchangeable-data-example-kill-1%
                    }%
                    \hspace{8mm}%
                    \input{%
                      figures/solving-techniques/%
                      interchangeable-data-example-kill-2%
                    }%
                  }%
  \end{minipage}

  \caption[Example of interchangeable data]%
          {%
            Example of interchangeable data and how these give rise to
            symmetries%
          }
  \labelFigure{interchangeable-data-example}
\end{figure}
%
This is another source for symmetric \glspl{solution}, which is illustrated in
\refFigure{interchangeable-data-example}.

Assume a \gls{UF graph} containing two \gls{copy-related.d} values, \irVar{v}[1]
and~\irVar{v}[2], that may both be connected to two \glspl{operand}~$p_1$
and~$p_2$ (\refFigure{interchangeable-data-example-annotated-graph}).
%
We say that a set of values constitute a chain of \gls!{interchangeable.d} if
they can be swapped in a \gls{solution} without affecting the \gls{program}
semantics, which is the case if the values are all \gls{copy-related.d} and none
is both \gls{define.d}[d] and \gls{use.d}[d] by some \gls{match}.
%
In the above example, \irVar{v}[1] and~\irVar{v}[2] constitute such a chain and
can therefore be swapped for $p_1$ and~$p_2$, giving rise to unwanted symmetric
\glspl{solution} (\refFigure{interchangeable-data-example-alt-solutions}).
%
The intuition here is to forbid \glspl{solution} containing ``cross-over''
connections between the values in a chain and the $\mVar{alt}$~\glspl{variable}.
%
As a precaution, however, we will exclude \glspl{operand} used by
\glspl{phi-match} due to the \gls{definition edge} which may require such
cross-over connections.

If we assume that there exists a partial order $\leq$ for~$\mDataSet$, then we
can remove these symmetries using the \gls!{value-precede-chain constraint},
which requires a sequence of \glspl{variable} to be sorted according to a given
chain of values.
%
Formally, the \gls{constraint} is defined as follows.
%
\begin{definition}[Value-Precede-Chain Constraint]%
  Let \mbox{$\mVar{x}_1, \ldots, \mVar{x}_k$} be a permutation of
  \glspl{variable}.
  %
  Let also $c$ be a 1-indexed sequence with $n$ elements.
  %
  Then
  %
  \begin{displaymath}
    \mValuePrecChain(c, \mVar{x}_1, \ldots, \mVar{x}_k)
    \equiv
    \bigcap_{1 \leq i < n}
    \mValuePrec(c[i], c[i+1], \mVar{x}[1], \ldots \mVar{x}[k]),
  \end{displaymath}
  %
  where
  \begin{displaymath}
    \mValuePrec(s, t, \mVar{x}_1, \ldots, \mVar{x}_k)
    \equiv
    \mSetBuilder{\langle d_1, \ldots, d_k \rangle}%
                {
                  \forall_{\! i} \: d_i \in \mDomain(\mVar{x}_i),
                  \forall_{\! i} \: d_i = t
                  \mImp \exists_{j} \: j < i \mAnd d_j = s
                }.
  \end{displaymath}
\end{definition}
%
For example, \mbox{$\mValuePrecChain(\langle 6, 5, 4 \rangle, \mVar{x}_1 \in
  \mSet{6}, \mVar{x}_2 \in \mSet{1}, \mVar{x}_3 \in \mSet{5}, \mVar{x}_4 \in
  \mSet{4})$} holds because the~4 is preceded by a~5, which in turn is preceded
by a~6, in the permutation of $\mVar{x}$~\glspl{variable}.
%
Likewise, \mbox{$\mValuePrecChain(\langle 5, 4 \rangle, \mVar{x}_1 \in \mSet{5},
  \mVar{x}_2 \in \mSet{1})$} also holds because 4 does not appear among the
$\mVar{x}$~\glspl{variable} (the fact that 5 appears in the permutation does
not matter).
%
However, \mbox{$\mValuePrecChain(\langle 5, 4 \rangle, \mVar{x}_1 \in \mSet{1},
  \mVar{x}_2 \in \mSet{4})$} does not hold because the~4 is not preceded by a~5.

Hence, if $\mInterchDataSet$ denotes the set of chains of
\gls{interchangeable.d} \glspl{datum} and \mbox{$\mOperandSet[\mPhi] \subseteq
  \mOperandSet$} denotes the set of \glspl{operand} used by \glspl{phi-match},
then the \gls{symmetry breaking.c} \gls{constraint} described above is modeled
as
%
\begin{equation}
  \begin{array}{c}
    \mValuePrecChain(c, \mVar{alt}[p_1], \ldots, \mVar{alt}[p_k]), \\
    \forall c \in \mInterchDataSet,
    \forall p_1, \ldots, p_k \in \mOperandSet \setminus \mOperandSet[\mPhi],
    p_1 \neq \cdots \neq p_k
    \mAnd
    \forall_{\! i} \: \mDataSet[p_i] \! = c.
  \end{array}
  \labelEquation{interchangeable-data-chain-precedence}
\end{equation}

Additional symmetries may appear due to \glspl{null-copy match}.
%
Returning to the previous example, if one of the two \glspl{copy node} need to
be covered using a \gls{copy match} derived from actual copy \gls{instruction},
then we are free to decide which.
%
Intuitively, we want to forbid \glspl{solution} where selected \glspl{null-copy
  match} appear to the ``left'' of a non-\gls{null-copy match}.
%
To this end, we make use of the \gls!{increasing constraint}, which requires a
sequence of \glspl{variable} to be assigned values in a non-strictly increasing
order.
%
Formally, the \gls{constraint} is defined as follows.
%
\begin{definition}[Increasing Constraint]%
  Let \mbox{$\mVar{x}_1, \ldots, \mVar{x}_k$} be a permutation of
  \glspl{variable}.
  %
  Then
  %
  \begin{displaymath}
    \mIncreasing(\mVar{x}_1, \ldots, \mVar{x}_k)
    \equiv
    \mSetBuilder{\langle d_1, \ldots, d_k \rangle}%
                {
                  \forall_{\! i} \: d_i \in \mDomain(\mVar{x}_i),
                  \forall_{\! i < k} \: d_i \leq d_{i+1}
                }.
  \end{displaymath}
\end{definition}
%
Let $\mInterchDataSet[\mCopy]$ denote the set of chains of \glspl{datum} that
can only be defined by \glspl{copy match}, $\mMatchSet[\mNull]$ and
$\mMatchSet[\mKill]$ denote the set of \glsshort{null match} and \glspl{kill
  match}, respectively, and \mbox{$\mDefSet(d) \subseteq \mMatchSet$} denote
the set of \glspl{match} that can define a \gls{datum}~$d$.
%
Using these definitions, this \gls{symmetry breaking.c} \glspl{constraint} is
modeled as
%
\begin{equation}
  \begin{array}{c}
    \mIncreasing(\mVar{sel}[m_1], \ldots, \mVar{sel}[m_k]), \\
    \forall c \in \mInterchDataSet[\mCopy],
    \forall m_1, \ldots, m_k \in \mMatchSet[\mNull]
                                 \setminus
                                 \mMatchSet[\mKill],
    \forall_{\! i} \: m_i = \min( \mDefSet(c[i])
                                \cap
                                \mMatchSet[\mNull]
                                \setminus
                                \mMatchSet[\mKill]
                              ).
  \end{array}
  \labelEquation{null-copy-matches-symmetry-breaking}
\end{equation}

\todo{describe constraint}

\begin{equation}
  \begin{array}{c}
    \mIncreasing(\mVar{sel}[m_1], \ldots, \mVar{sel}[m_k]), \\
    \forall c \in \mInterchDataSet[\mCopy],
    \forall m_1, \ldots, m_k \in \mMatchSet[\mKill],
    \forall_{\! i} \: m_i = \min( \mDefSet(c[i])
                                \cap
                                \mMatchSet[\mKill]
                              ).
  \end{array}
  \labelEquation{kill-matches-symmetry-breaking}
\end{equation}


\section{Presolving}
\labelSection{st-presolving}

\subsection{Dominated matches}
\subsection{Illegal matches}
\subsection{Redundant kill instructions}
\subsection{Redundant null-copy instructions}


\section{Experimental Evaluation}
\subsection{Refined Objective Function Vs. Naive Objective Function}
\subsection{With Or Without Presolving}
\subsection{With Or Without Lower And/Or Upper Cost Bound}
\subsection{With Or Without Implied and Dominance Breaking Constraints}

\section{Discussion}


\section{Summary}
\labelSection{st-summary}

\todo{write summary}
