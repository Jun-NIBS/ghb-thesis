% Copyright (c) 2017, Gabriel Hjort Blindell <ghb@kth.se>
%
% This work is licensed under a Creative Commons 4.0 International License (see
% LICENSE file or visit <http://creativecommons.org/licenses/by/4.0/> for a copy
% of the license).

\chapter[Experimental Evaluation Using the State of the Art]%
        {Experimental Evaluation\\ Using the State of the Art}
\labelChapter{exp-evaluation-using-the-state-of-the-art}

This chapter evaluates how our approach compares against a state-of-the-art
\gls{compiler}.
%
This is done in \refSection{evaluation-unison-vs-llvm}.
%
Since our approach is able to leverage selection of \gls{SIMD.i}
\glspl{instruction}, we also evaluate this impact in
\refSection{evaluation-with-or-without-simds}.


\section{Unison \versus LLVM}
\labelSection{evaluation-unison-vs-llvm}

We evaluate the impact of our approach by comparing the cost (that is, the total
number of cycles, as described in \refSection{cm-objective-function} on
\refPageOfSection{cm-objective-function}) of \glspl{solution} produced by our
approach with the \glspl{solution} produced by \mbox{\gls{LLVM} 3.8} -- an
existing, state-of-the-art \gls{compiler}.


\paragraph{Setup}

When filtering, we remove all \glspl{function} that have less than
\num{50}~\gls{LLVM} \gls{IR} \glspl{instruction} and greater than
\num{200}~\glspl{instruction}.
%
Anything smaller will most likely not show any gain using our approach, and
anything larger will lead to unreasonably long experiment runtimes.
%
This leaves a pool of \num{284}~\glspl{function}, on which we then perform
sampling.

When solving, we apply a time limit of \SI{600}{\s} to the \gls{constraint
  solver}.
%
This is to curb experiment runtimes.
%
For any given \gls{function}, the last \gls{solution} found is considered
optimal if and only if the \glsshort{constraint solver} has finished its
execution within the time limit.
%
As upper bound for a given \gls{function}, we take the cost for the
\gls{solution} computed by \gls{LLVM}.


\paragraph{Results}

\input{\expDir/unison-vs-llvm-hexagon5-cycles-speedup.stats}

\RefFigure{unison-vs-llvm-cycles-plot} shows the normalized \gls{solution} costs
for our approach, with \gls{LLVM} as \gls{baseline} and our approach as
\gls{subject}.
%
\begin{figure}
  \centering%
  \maxsizebox{\textwidth}{!}{%
    \trimBarchartPlot{%
      \input{\expDir/unison-vs-llvm-hexagon5-cycles-speedup.plot}%
    }%
  }

  \caption[Plot for evaluating the impact of our approach on code quality]%
          {%
            Solution costs produced by our approach, normalized to those
            produced by LLVM.
            %
            GMI:~\printGMI{%
              \UnisonVsLlvmHexagonFiveCyclesSpeedupCyclesRegularSpeedupGmean%
            },
            CI:~\printGMICI{%
              \UnisonVsLlvmHexagonFiveCyclesSpeedupCyclesRegularSpeedupCiMin%
            }{%
              \UnisonVsLlvmHexagonFiveCyclesSpeedupCyclesRegularSpeedupCiMax%
            }.
            %
            The constraint model uses an upper bound computed by LLVM.
            %
            \Glspl{function} whose bars are marked with two dots are those for
            which the \gls{subject} does not find the optimal solution, and
            \glspl{function} marked with \barValueNoSolution{} are those where
            the solution produced by \gls{LLVM} is already optimal \wrt the
            model%
          }
  \labelFigure{unison-vs-llvm-cycles-plot}
\end{figure}
%
The size of the \glspl{UF graph} range from \num{189} to
\num{1524}~\glspl{node}.
%
The costs range from
\printCycles{\UnisonVsLlvmHexagonFiveCyclesSpeedupCyclesAvgMin} to
\printCycles{\UnisonVsLlvmHexagonFiveCyclesSpeedupCyclesAvgMax}, with a maximum
coefficient of variation of
\num{\UnisonVsLlvmHexagonFiveCyclesSpeedupCyclesCvMax}.
%
The solving times range from
\printSolvingTime{\UnisonVsLlvmHexagonFiveCyclesSpeedupPrePlusSolvingTimeAvgMin}
to
\printSolvingTime{\UnisonVsLlvmHexagonFiveCyclesSpeedupPrePlusSolvingTimeAvgMax}
with a \gls{CV} of
\num{\UnisonVsLlvmHexagonFiveCyclesSpeedupPrePlusSolvingTimeCvMax}.
%
The \gls{GMI} is \printGMI{%
  \UnisonVsLlvmHexagonFiveCyclesSpeedupCyclesRegularSpeedupGmean%
} with \gls{CI}~\printGMICI{%
  \UnisonVsLlvmHexagonFiveCyclesSpeedupCyclesRegularSpeedupCiMin%
}{%
  \UnisonVsLlvmHexagonFiveCyclesSpeedupCyclesRegularSpeedupCiMax%
}.

We see that our approach produces \glspl{solution} with significantly less
cost than those produced by \gls{LLVM} (up to~\printSpeedup{%
  \UnisonVsLlvmHexagonFiveCyclesSpeedupCyclesZeroCenteredSpeedupMax%
} improvement).
%
These improvements are predominatly due to the combination of \gls{global.is}
\gls{instruction selection}, \gls{global code motion}, and \gls{block ordering}.
%
In three cases (\cCode*{alloc\_save\_spac}, \cCode*{gp\_enumerate\_fi}, and
\cCode*{gpk\_open}), for example, our approach is able to reduce cost by lifting
computations, in particular constant loads, out of \glspl{block} with high
execution frequency into \glspl{block} with lower frequency.
%
In \cCode*{alloc\_save\_spac}, our approach is also able to move an addition and
memory \gls{operation} into the same \gls{block} and implement both using a
single auto-increment memory \gls{instruction}, whereas \gls{LLVM} must
implement these computations using two \glspl{instruction}.
%
These improvements are only possible due to integrating \gls{global.is}
\gls{instruction selection} with \gls{global code motion}.

In three other cases (\cCode*{jpeg\_read\_header}, \cCode*{gl\_TexImage3DEX},
and \cCode*{gl\_EnableClient}), our approach is able to reorder the
\glspl{block} to remove one to two jump \glspl{instruction}.
%
These improvements are only possible when integrating \gls{global.is}
\gls{instruction selection} with \gls{block ordering}.


\paragraph{Conclusions}

Based on the observations above, we conclude that our approach generates code of
equal or better quality compared to the state of the art for up to medium-sized
\glspl{function}.


\section{Impact of SIMD instructions}
\labelSection{evaluation-with-or-without-simds}

We evaluate the impact of being able to select \gls{SIMD.i} \glspl{instruction}
by comparing the cost of \glspl{solution} produced from two \glspl{pattern set}:
%
\begin{patternList}
  \item \labelPattern{no-simd}
    one derived from \gls{Hexagon} with no \gls{SIMD.i} \glspl{instruction}
  \item \labelPattern{with-simd}
    one with \num{2}- and \num{4}-way \cCode*{add}, \cCode*{sub}, \cCode*{and},
    and \cCode*{or} \glspl{instruction}
\end{patternList}.


\paragraph{Setup}

When filtering, we again all \glspl{function} that have less than
\num{50}~\gls{LLVM} \gls{IR} \glspl{instruction} and greater than
\num{150}~\glspl{instruction}.
%
Anything smaller will most likely not have enough data parallelism for selection
of \gls{SIMD.i} \glspl{instruction}, anything larger will lead to unreasonably
long experiment runtimes.
%
But to increase the chance of data parallelism, we also remove all
\glspl{function} not containing at least two addition, subtraction, logical-and,
or logical-or \glspl{instruction}.
%
This leaves a pool of \num{221}~\glspl{function}, from which
\num{20}~\glspl{function} are sampled using the same method as before.
%
In this experiment, we do not apply an upper bound in this case as that may
prevent interesting \gls{solution} that make use of \gls{SIMD.i}
\gls{instruction}.

Note that no \gls{loop unrolling}%
%
\footnote{%
  \Gls!{loop unrolling} is the task of duplicating the body of a loop in order
  to increase data parallelism.
  %
  However, this is done at the cost of increased code size.%
}
%
is performed on any of the \glspl{function} prior to \gls{instruction
  selection}.


\paragraph{Results}

\input{\expDir/simd-vs-without-cycles-speedup.stats}

\RefFigure{simd-vs-without-cycles-plot} shows the normalized \gls{solution}
costs for the two \glspl{pattern set} describe above, with \gls{pattern
  set}~\refPattern{no-simd} as \gls{baseline} and \gls{pattern
  set}~\refPattern{with-simd} as \gls{subject}.
%
\begin{figure}
  \centering%
  \maxsizebox{\textwidth}{!}{%
    \trimBarchartPlot{%
      \input{\expDir/simd-vs-without-cycles-speedup.plot}%
    }%
  }

  \caption[Plot for evaluating the impact of SIMD instructions on code quality]%
          {%
            Normalized solution costs for two pattern sets:
            %
            \begin{inlinelist}[itemjoin={, }, itemjoin*={, and}]
              \item one without SIMD instructions (baseline)
              \item one with such instruction (subject)
            \end{inlinelist}.
            %
            GMI:~\printGMI{%
              \SimdVsWithoutCyclesSpeedupCyclesRegularSpeedupGmean%
            },
            CI:~\printGMICI{%
              \SimdVsWithoutCyclesSpeedupCyclesRegularSpeedupCiMin%
            }{%
              \SimdVsWithoutCyclesSpeedupCyclesRegularSpeedupCiMax%
            }.
            %
            \Glspl{function} whose bars are marked with two dots are those
            for which the \gls{subject} does not find the optimal solution%
          }
  \labelFigure{simd-vs-without-cycles-plot}
\end{figure}
%
The costs range from
\printMinCycles{%
  \SimdVsWithoutCyclesSpeedupCyclesAvgMin,
  \SimdVsWithoutCyclesSpeedupBaselineCyclesAvgMin
} to
\printMaxCycles{%
  \SimdVsWithoutCyclesSpeedupCyclesAvgMax,
  \SimdVsWithoutCyclesSpeedupBaselineCyclesAvgMax
}, with a \gls{CV} of
\numMaxOf{
  \SimdVsWithoutCyclesSpeedupCyclesCvMax,
  \SimdVsWithoutCyclesSpeedupBaselineCyclesCvMax
}.
%
The solving times from
\printMinSolvingTime{%
  \SimdVsWithoutCyclesSpeedupPrePlusSolvingTimeAvgMin,
  \SimdVsWithoutCyclesSpeedupBaselinePrePlusSolvingTimeAvgMin
} to
\printMaxSolvingTime{%
  \SimdVsWithoutCyclesSpeedupPrePlusSolvingTimeAvgMax,
  \SimdVsWithoutCyclesSpeedupBaselinePrePlusSolvingTimeAvgMax
}, with a \gls{CV} of
\numMaxOf{
  \SimdVsWithoutCyclesSpeedupPrePlusSolvingTimeCvMax,
  \SimdVsWithoutCyclesSpeedupBaselinePrePlusSolvingTimeCvMax
}.
%
The \gls{GMI} is \printGMI{%
  \SimdVsWithoutCyclesSpeedupCyclesRegularSpeedupGmean%
} with \gls{CI}~\printGMICI{%
  \SimdVsWithoutCyclesSpeedupCyclesRegularSpeedupCiMin%
}{%
  \SimdVsWithoutCyclesSpeedupCyclesRegularSpeedupCiMax%
}

We see that the \gls{pattern set}~\refPattern{with-simd} yields \glspl{solution}
with significantly less cost than those yielded by \gls{pattern
  set}~\refPattern{no-simd} (up to~\printSpeedup{%
  \SimdVsWithoutCyclesSpeedupCyclesZeroCenteredSpeedupMax%
} improvement).
%
The five cases with less cost (\cCode*{debug\_print\_str},
\cCode*{gl\_read\_alpha}, \cCode*{gx\_curve\_cursor}, \cCode*{mp\_dmul}, and
\cCode*{zero}), our approach is able to combine pairs of additions or
subtractions into \num{2}-way \gls{SIMD.i} \glspl{instruction}.
%
In addition, in one of these cases (\cCode*{gl\_read\_alpha}) the additions
originally reside in different \glspl{block}, but due to \gls{global code
  motion} our approach is able to move the computations to the same \gls{block}
and implement these using a single \gls{instruction}.


\paragraph{Conclusions}

Based on the observations above, we conclude that there is sufficient data
parallelism to be exploited through selection of \gls{SIMD.i}
\glspl{instruction} without having to resort to \gls{loop unrolling}.
%
In addition, this exploitation is benefitted from \gls{global code motion} as
that allows computations to be gathered from different \glspl{block} and
implemented using a single \gls{SIMD.i} \gls{instruction}.
