% Copyright (c) 2017, Gabriel Hjort Blindell <ghb@kth.se>
%
% This work is licensed under a Creative Commons 4.0 International License (see
% LICENSE file or visit <http://creativecommons.org/licenses/by/4.0/> for a copy
% of the license).

\chapter{Introduction}
\labelChapter{introduction}

\enlargethispage{3pt}

Processors are built to execute a vast range of \glspl{program}, from tiny
\emph{Hello, world!} samples to large-scale Earth simulations.
%
Most importantly, the processors are built to minimize the execution time for
these \glspl{program}.
%
To this end, CPU manufacturers continuously extend their processors with new,
sophisticated \glspl{instruction} that allow complex computations to be executed
using fewer \glspl{instruction}.
%
Such \glspl{instruction} are especially common in \glspl{DSP} that appear in
most contemporary mobile phones.
%
But while the technology behind modern processors continues to advance, the
techniques for automatically making use of the \glspl{instruction} have not.
%
In fact, the state-of-the-art \glspl{compiler} -- these are tools for
translating \glspl{program} into \gls{assembly code} -- essentially apply the
same techniques for selecting \glspl{instruction} that were used in the 1980s.


\paragraph{Problem Statement}

Due to underlying assumptions, many of the \glspl{instruction} currently
available in modern processors cannot be handled by these techniques.
%
In particular, they rely on representations that are too limited for modeling
these \glspl{instruction}.
%
Instead, \gls{compiler} developers are forced to implement hand-written routines
for checking whether a specific \gls{instruction} is applicable and, if so,
greedily selecting it.
%
With over \num{100}~million microprocessors being shipped every
quarter~\cite{Intel:2014:NewsRelease}, through release cycles that become
shorter and shorter, there is a growing need for new and improved
\gls{instruction selection} techniques.

Furthermore, the set of selectable \glspl{instruction} is highly dependent on
other \gls{compiler} tasks.
%
One such task is \gls{global code motion}, which involves moving computations
from one part of the \gls{program} to another.
%
Integrating \gls{global code motion} with \gls{instruction selection} enables a
larger set of combinations of computations, some of which may be implemented
using sophisticated \glspl{instruction}.
%
Another task is \gls{block ordering}, which involves placing the \gls{program}
\glspl{block} in a consecutive sequence.
%
Depending on the processor, one set of selected \glspl{instruction} may impact
the possible \gls{block} sequence and vice versa.
%
Consequently, in order to generate high-quality code, these tasks must be
performed in unison.


\paragraph{Universal Instruction Selection}

In this dissertation, I introduce \gls!{universal instruction selection},\!%
%
\footnote{%
  The source code is freely available on
  {\relsize{-.5}{\url{github.com/unison-code/uni-instr-sel}}}.%
}
%
a new approach that addresses the problems recently described.
%
Outlined in \refFigure{approach-overview}, the approach is the first to combine
\gls{instruction selection} with \gls{global code motion} and \gls{block
  ordering}.
%
\begin{figure}
  \centering%
  \input{figures/introduction/approach-overview}

  \caption{Overview of the approach}
  \labelFigure{approach-overview}
\end{figure}
%
In doing so, the approach alleviates selection of sophisticated
\glspl{instruction} that would otherwise not have been selectable.

To handle the combinatorial nature of these problems, I base the approach on
\glsdesc{CP}.
%
I formulate on a novel combinatorial model that is simpler and more flexible
compared to the techniques currently used by modern \glspl{compiler}.
%
In addition, it captures crucial features that are ignored by other, existing
combinatorial approaches.
%
I also propose extensions for integrating \gls{instruction scheduling} and
\gls{register allocation}, which are two other \gls{code generation} tasks known
to impact \gls{instruction selection}.

The model is enabled by a novel, \gls{graph}-based representation that unifies
data flow and control flow for entire \glspl{function}.
%
Not only is this representation crucial for combining \gls{instruction
  selection} with \gls{global code motion}, it also enables \glspl{instruction}
whose behavior contains both data and control flow to be modeled as
\glspl{graph}.
%
Hence there is no longer any need for hand-written routines to handle
\glspl{instruction} that violate underlying assumptions about the
\gls{instruction set}.


\section{Thesis Statement}
\labelSection{intro-thesis-statement}

\begin{statement}
  \Glsdesc{CP} is a flexible, practical, competitive, and
  extensible approach for combining \gls{global.is} \gls{instruction selection},
  \gls{global code motion}, and \gls{block ordering}.
\end{statement}
%
By \emph{flexible}, it means that the approach can handle hardware architectures
with a rich \gls{instruction set}.
%
By \emph{practical}, it means that the approach can select \glspl{instruction}
for \glspl{program} of sufficient complexity and scales to medium-sized
\glspl{function} (measured in hundreds of \glspl{operation}).
%
By \emph{competitive}, it means that the approach generates code of equal or
better quality compared to the state of the art.
%
By \emph{extensible}, it means that the approach can be extended to integrate
other \gls{code generation} tasks.


\section{Motivation}
\labelSection{intro-motivation}

A \gls!{compiler} is a tool that takes a \gls{program}, written in some
programming language, as input and produces equivalent \gls{assembly code} for a
specific processor, called the \gls!{target machine}, as output.
%
As shown in \refFigure{compiler-overview}, a \gls{compiler} typically consists
of three parts:%
%
\begin{figure}
  \centering%
  \input{figures/introduction/compiler-overview}

  \caption{Overview of a typical compiler}
  \labelFigure{compiler-overview}
\end{figure}
%
\begin{inlinelist}[itemjoin={; }, itemjoin*={; and}]
  \item a \gls!{frontend}, which performs syntactic and semantic analysis and
    transforms the program into an \gls!{IR}
  \item an \gls!{optimizer} (sometimes called \gls!{middle-end}), which performs
    target-independent optimizations
  \item a \gls!{backend}, which performs \gls{code generation}
\end{inlinelist}.

The \gls{optimizer} is arguably the largest component of any \gls{compiler},
consisting of many tasks such as \gls{constant folding}, \gls{dead code
  elimination}, and \gls{loop unrolling}.
%
Another such optimization is \gls!{global code motion}, where \glspl{operation}
are moved from one \gls{basic block} to another, which is done mainly to move
expensive \glspl{operation} into \glspl{block} with lower execution frequency.

The \gls{backend} also consists of several tasks, of which three
typically are most promiment:%
%
\begin{inlinelist}[itemjoin={; }, itemjoin*={; and}]
  \item \gls!{instruction selection}, where \glspl{instruction} implementing the
    given \gls{program} are selected
  \item \gls!{register allocation}, where \gls{virtual.temp} \glspl{temporary}
    are assigned to \glspl{register}
  \item \gls!{instruction scheduling}, where \glspl{instruction} are reordered
    to increase instruction-level parallelism
\end{inlinelist}.
%
Another code generation task of interest is \gls!{block ordering}, where the
\glspl{basic block} are rearranged in order to minimize the number of jump
\glspl{instruction}.


\subsection{The Need for New Techniques and Representations}
\labelSection{intro-saturated-arithmetic}

\RefFigure{isel-gcmotion-example} shows a program that computes the saturated
sums of two integer arrays.
%
\begin{filecontents*}{isel-gcmotion-example.c}
int i = 0;
while (i < N) {
  int a = A[i];
  int b = B[i];
  int c = a + b;
  if (MAX < c) c = MAX;
  C[i] = c;
  i++;
}
\end{filecontents*}
%
\begin{figure}
  \centering%

  \mbox{}%
  \hfill%
  \subcaptionbox{C code\labelFigure{isel-gcmotion-example-c}}%
                {%
                  \begin{lstpage}{42mm}%
                    \lstinputlisting[language=c]{isel-gcmotion-example.c}%
                  \end{lstpage}%
                }%
  \hfill\hfill%
  \subcaptionbox{Corresponding IR and control-flow graph%
                 \labelFigure{isel-gmotion-example-ir}}%
                [64mm]%
                {\input{figures/introduction/isel-gcmotion-example-ir}}%
  \hfill%
  \mbox{}

  \caption[%
            Example illustrating the need for new techniques and the interaction
            between instruction selection and global code motion%
          ]{%
            Example to illustrate the need for new techniques and the
            interaction between instruction selection and global code motion.
            %
            The program computes the saturated sums of two arrays \irVar*{A} and
            \irVar*{B} as a new array~\irVar*{C}, all of which are assumed to be
            of equal lengths and stored in memory.
            %
            The variables \irVar*{N} and \irVar*{MAX} are constants representing
            the array length and the upper limit, respectively.
            %
            An integer is assumed to be 4~bytes%
          }
  \labelFigure{isel-gcmotion-example}%
\end{figure}
%
In \gls!{saturation arithmetic}, the result of an arithmetic \gls{operation}
will always stay within a range fixed by a minimum and maximum value.
%
If the \gls{operation} would produce a value outside of this range, then the
value is set (``clamped'') to the closest limit, thus becoming ``saturated''.

Assume a \gls{target machine} that has an instruction capable of implementing
the saturated-add \gls{operation} used in the \gls{program} shown in
\refFigure{isel-gcmotion-example}.
%
Hence the \gls{instruction} would implement the following five
\glspl{operation}:%
%
\begin{inlinelist}[itemjoin={, }, itemjoin*={, and}]
  \item the \irAdd*{\irVar*{a}}{\irVar*{b}} addition
  \item the \irLE*{\irVar*{MAX}}{\irVar*{c}} comparison
  \item the conditional jump to either of blocks~\irBlock*{b4} and~\irBlock*{b5}
  \item the \irAssign*{\irVar*{c}}{\irVar*{MAX}} assignment
  \item the unconditional jump to~\irBlock*{b5}
\end{inlinelist}.
%
Selecting this \gls{instruction} can have tremendous impact on performance.
%
Assume, for example, that each \gls{operation} can be implemented using an
\gls{instruction} that takes one cycle to execute. Hence executing one iteration
of the loop takes \num{16}~cycles, and selecting the saturated-add
\gls{instruction} reduces the execution time by \SI{25}{\percent}.

Existing \gls{instruction selection} techniques and representations, however, do
not support selection of such \glspl{instruction}.
%
Since the \glspl{operation} above reside in separate \glspl{block}
(\irBlock*{b3} and \irBlock*{b4}), making use of the saturated-add
\gls{instruction} requries an \gls{instruction selector} that is capable of
processing multiple \glspl{basic block} simultaneously.
%
In comparison, traditional \gls{instruction selection} techniques only consider
one \gls{basic block} at a time.
%
Morever, most approaches represent the \glspl{instruction} as \glspl{graph}.
%
As the saturated-add \gls{instruction} contains \glspl{operation} for both data
and control flow, modeling it as a \gls{graph} requires a representation that
captures both data and control flow.
%
In comparison, existing representations only capture data flow.


\subsection{For Combining Instruction Selection and Global Code Motion}

Assume that the \gls{target machine} also has a \glsunset{SIMD.i}\gls{SIMD.i}
\gls{instruction} for addition.\!%
%
\footnote{%
  A \glsreset{SIMD.i}\gls!{SIMD.i}[ \gls{instruction}] is an \gls{instruction}
  that executes the same \gls{operation} over multiple sets of input data.%
}
%
Revisiting the example shown in \refFigure{isel-gcmotion-example}, there are
four additions in the \gls{program} (\irAdd*{\irVar*{A}}{\irTemp*{2}},
\irAdd*{\irVar*{B}}{\irTemp*{2}}, \irAdd*{\irVar*{C}}{\irTemp*{2}}, and
\irAdd*{\irVar*{i}}{\irVar*{1}}) which are independent from one another and can
therefore be executed in parallel.
%
Assuming again that all \glspl{instruction} takes one cycle to execute,
implementing these four additions using a single \gls{SIMD.i} \gls{instruction}
would improve performance by almost \SI{19}{\percent}.
%
This requires that the two additions in block~\irBlock*{b5} be moved to
block~\irBlock*{b4}, which is the task of \gls{global code motion}.
%
However, as \gls{global code motion} is commonly considered to be a
target-independent optimization, it is often done before \gls{code generation}.
%
Consequently, the \gls{global code mover} may take decisions which are
detrimental for the \gls{instruction selector}.


\subsection{For Taking Cost of Data Copying Into Account}

Although selecting \gls{SIMD.i} \glspl{instruction} may significantly improve
code quality -- like in the previous example -- doing so carelessly may also
have the opposite effect.
%
Assume, for example, that the \gls{SIMD.i} \gls{instruction} uses a limited set
of registers.
%
If the other selected \glspl{instruction} cannot directly write to and read from
these registers, then additional \glspl{instruction} must be emitted to copy the
values between the general registers and the \gls{SIMD.i} registers.
%
In the case of the program shown in \refFigure{isel-gcmotion-example}, eight
such \glspl{instruction} would be needed, leading to a slowdown of over
\SI{31}{\percent}.
%
These restrictions must be known by the \gls{instruction selector} to make
effective use of \gls{SIMD.i} \glspl{instruction}.


\subsection{For Combining Instruction Selection and Block Ordering}

\RefFigure{isel-blorder-example} shows a \gls{function} that keeps calling
another \gls{function} (with side effects) until it returns a non-zero value.
%
\begin{filecontents*}{isel-blorder-example.c}
int f() {
  int a;
  do {
    a = g();
  } while (a == 0);
  return a;
}
\end{filecontents*}
%
\begin{figure}
  \centering%
  \subcaptionbox{C code\labelFigure{isel-blorder-example-c}}%
                {%
                  \begin{lstpage}{36mm}%
                    \lstinputlisting[language=c]{isel-blorder-example.c}
                  \end{lstpage}%
                }%
  \hspace{5mm}%
  \subcaptionbox{%
                  Corresponding IR and control-flow graph%
                  \labelFigure{isel-blorder-example-ir}%
                }%
                [64mm]%
                {\input{figures/introduction/isel-blorder-example-ir}}%

  \vspace{\betweensubfigures}

  \subcaptionbox{%
                  Selecting basic jump instruction, after block ordering.
                  %
                  Cycle count: 6%
                  \labelFigure{isel-blorder-example-code-1}%
                }%
                {%
                  \figureFontSize%
                  \begin{tabular}{%
                                   >{\instrFont{}}l@{\hspace{.5em}}%
                                   >{\instrFont{}}l@{\hspace{.5em}}%
                                   >{\instrFont{}}l%
                                 }
                    \toprule
                    b1: & call & a $\leftarrow$ g()\\
                        & cmp  & \instrTemp{1} $\leftarrow$
                                 \instrEQ{\instrVar{a}}{\instrVar{0}}\\
                        & jmp  & \instrTemp{1}, \instrBlock{b1}\\
                    b2: & ret  & \instrVar{a}\\
                    \bottomrule
                  \end{tabular}%
                }%
  \hfill%
  \subcaptionbox{%
                  Selecting complex jump instruction, before block ordering.
                  %
                  Cycle count: 5%
                  \labelFigure{isel-blorder-example-code-2}%
                }%
                [38mm]%
                {%
                  \figureFontSize%
                  \begin{tabular}{%
                                   >{\instrFont{}}l@{\hspace{.5em}}%
                                   >{\instrFont{}}l@{\hspace{.5em}}%
                                   >{\instrFont{}}l%
                                 }
                    \toprule
                    b1: & call & a $\leftarrow$ g()\\
                        & jmp  & \instrNE{\instrVar{a}}{\instrVar{0}},
                                 \instrBlock{b2}\\
                    \\
                    b2: & ret  & \instrVar{a}\\
                    \bottomrule
                  \end{tabular}%
                }
  \hfill%
  \subcaptionbox{%
                  Selecting complex jump instruction, after block ordering.
                  %
                  Cycle count: 8%
                  \labelFigure{isel-blorder-example-code-3}%
                }%
                [39mm]%
                {%
                  \figureFontSize%
                  \begin{tabular}{%
                                   >{\instrFont{}}l@{\hspace{.5em}}%
                                   >{\instrFont{}}l@{\hspace{.5em}}%
                                   >{\instrFont{}}l%
                                 }
                    \toprule
                    b1: & call & a $\leftarrow$ g()\\
                        & jmp  & \instrNE{\instrVar{a}}{\instrVar{0}},
                                 \instrBlock{b2}\\
                        & jmp  & \instrBlock{b1}\\
                    b2: & ret  & \instrVar{a}\\
                    \bottomrule
                  \end{tabular}%
                }

  \caption[%
            Example illustrating the interaction between instruction
            selection and block ordering%
          ]{%
            Example to illustrate the interaction between instruction
            selection and block ordering.
            %
            The function \irCode*{f} calls another function \irCode*{g} until it
            returns a non-zero value, and then returns that value%
          }
  \labelFigure{isel-blorder-example}%
\end{figure}
%
Assume that the \gls{target machine} has three \glspl{instruction} for handling
control flow:%
%
\begin{inlinelist}[itemjoin={; }, itemjoin*={; and}]
  \item a \mbox{{\instrFont* jmp} $p$, $b$} \gls{instruction}, which
    branches to block~$b$ if the value in register~$p$ corresponds the Boolean
    value~$\mathit{true}$
  \item a \mbox{{\instrFont* jmp} $r \neq 0$, $b$} \gls{instruction}, which
    branches to block~$b$ if the condition \mbox{$r \neq 0$} holds, where $r$
    is a register
  \item a \mbox{{\instrFont* jmp} $b$} \gls{instruction}, which
    unconditionally branches to block~$b$
\end{inlinelist}.
%
Assume also that these branch \glspl{instruction} take three cycles compared to
the other \glspl{instruction} in the \gls{target machine}, which take one cycle.

At first glance it appears that only the first jump \gls{instruction} is
selectable for implementing the conditional branch (see
\refFigure{isel-blorder-example-code-1}), leading to a total of six cycles for
the entire \gls{function}.
%
But by flipping the condition and swapping block labels (conditionally jumping
to \irBlock*{b2} instead of \irBlock*{b1}), the more complex jump
\gls{instruction} becomes selectable (see
\refFigure{isel-blorder-example-code-2}), bringing the cycle count to five
cycles and thus reducing the execution time by almost \SI{17}{\percent}.
%
However, although this decision may appear better at the point of
\gls{instruction selection}, it necessitates an additional jump
\gls{instruction} when ordering the \glspl{block} (because block~\irBlock*{b1}
cannot fall-through to the top of itself; see
\refFigure{isel-blorder-example-code-3}).
%
This code takes eight cycles to execute, thus leading to a slowdown of
\SI{33}{\percent}.
%
The \gls{instruction selector} must therefore be aware of additional jump
\glspl{instruction} that may be required when making such decisions.


\section{Contributions}
\labelSection{intro-contributions}

In this dissertation, I make six contributions to the areas of \gls{code
  generation} and \glsdesc{CP}:
%
\begin{contributions}
  \item \labelContribution{survey}
    I present a comprehensive and systematic survey that
    \begin{contributions}
      \item \labelContribution{survey-spanning}
        examines over four decades of research on \gls{instruction selection},
        covering a significantly wider scope and timespan compared to existing
        surveys \cite{Cattell:1977, GanapathiEtAl:1982:Survey, Lunell:1983,
          Leupers:2000:Survey, BoulytchevLomov:2001} which are either too old
        or incomplete.
    \end{contributions}
    The survey structures the approaches according to two dimensions:
    \begin{contributions}[resume]
      \item \labelContribution{survey-principles}
        the fundamental \gls{principle} -- \gls{macro expansion}, \gls{tree
          covering}, \gls{DAG covering}, or \gls{graph covering} -- that they
        apply, and
    \end{contributions}
    \begin{contributions}[resume]
      \item \labelContribution{survey-instruction-characteristics}
        the \glspl{instruction characteristic} -- \gls{single-output.ic},
        \gls{multi-output.ic}, \gls{disjoint-output.ic}, \gls{inter-block.ic},
        and \gls{interdependent.ic} -- that they support.
    \end{contributions}
    %
    In addition, the survey
    \begin{contributions}[resume]
      \item \labelContribution{survey-problem-identification}
        identifies connections between \gls{instruction selection} and other
        \gls{code generation} problems that have yet to be investigated.
    \end{contributions}
  \item \labelContribution{representations}
    I introduce a novel \gls{program} and \gls{instruction} representation
    that
    \begin{contributions}
      \item \labelContribution{rep-data-and-control-flow}
        captures both data and control flow for entire \glspl{function} and
        \glspl{instruction},
    \end{contributions}
    which enables
    \begin{contributions}[resume]
      \item \labelContribution{rep-complex-instructions}
        an unprecedented range of instruction behaviors to be captured and
        modeled as \glspl{pattern}.
    \end{contributions}
    In addition, the representation is crucial for
    \begin{contributions}[resume]
      \item \labelContribution{rep-combining-problems}
        combining \gls{instruction selection} and \gls{global code motion} --
        two problems that have until now been considered separately from one
        another -- and solving these two problems in unison.
    \end{contributions}
  \item \labelContribution{constraint-model}
    I introduce a \gls{constraint model} and related transformations for
    \gls{universal instruction selection} which, for the first time, enables
    \begin{contributions}
      \item \labelContribution{cp-uniform-selection}
        uniform selection of data and control \glspl{instruction},
    \end{contributions}
    and integration of
    \begin{contributions}[resume]
      \item \labelContribution{cp-global-instruction-selection}
        \gls{global.is} \gls{instruction selection} with
      \item \labelContribution{cp-global-code-motion}
        \gls{global code motion}.
    \end{contributions}
    In addition, the \gls{constraint model} integrates
    \begin{contributions}[resume]
      \item \labelContribution{cp-data-copying}
        \gls{data copying},
      \item \labelContribution{cp-value-reuse}
        \gls{value reuse}, and
      \item \labelContribution{cp-block-ordering}
        \gls{block ordering}.
    \end{contributions}
  \item \labelContribution{solving-techniques}
    I introduce techniques to improve solving of the \gls{constraint model}.
  \item \labelContribution{experiments}
    I present thorough experiments demonstrating that the approach scales to
    medium-sized \glspl{program} and yields equal or better code than the state
    of the art.
  \item \labelContribution{integration}
    I propose extensions of the \gls{constraint model} for integrating
    \gls{instruction scheduling} and \gls{register allocation}, two other
    important problems of \gls{code generation}.
\end{contributions}
%
\refTable{contributions-per-chapter} shows in which part of the dissertation
each contribution is manifested.

\begin{table}
  \centering%
  \begin{tabular}{c@{\qquad}*{6}{c}}
    \toprule
      \tabhead chapter
    & \tabhead\refContribution{survey}
    & \tabhead\refContribution{representations}
    & \tabhead\refContribution{constraint-model}
    & \tabhead\refContribution{solving-techniques}
    & \tabhead\refContribution{experiments}
    & \tabhead\refContribution{integration}\\
    \midrule
    \refChapter*{existing-isel-techniques-and-reps}
    & \supportYes
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo\\
    \refChapter*{universal-representation}
    & \supportNo
    & \supportYes
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo\\
    \refChapter*{constraint-model}
    & \supportNo
    & \supportNo
    & \supportYes
    & \supportNo
    & \supportNo
    & \supportNo\\
    \refChapter*{solving-techniques}
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportYes
    & \supportNo
    & \supportNo\\
    \refChapter*{exp-evaluation-using-the-state-of-the-art}
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportYes
    & \supportNo\\
    \refChapter*{proposed-model-extensions}
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportYes\\
    \refAppendix*{macro-expansion}
    & \supportYes
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo\\
    \refAppendix*{tree-covering}
    & \supportYes
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo\\
    \refAppendix*{dag-covering}
    & \supportYes
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo\\
    \refAppendix*{graph-covering}
    & \supportYes
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo\\
    \bottomrule
  \end{tabular}

  \caption{Contributions per chapter}
  \labelTable{contributions-per-chapter}
\end{table}


\section{Publications}
\labelSection{intro-publications}

This dissertation is based on material presented in the following publications:


\paragraph{Books}

\begin{publications}
  \item \labelPublication{survey-book}
    \fullcite{HjortBlindell:2016:Survey}.
\end{publications}


\paragraph{Conference Papers}

\begin{publications}[resume]
  \item \labelPublication{cp-paper}
    \fullcite{HjortBlindellEtAl:2015:CP}.
    %
    \begin{authorsContribution}
      I designed and implemented the work presented in the paper, oversaw the
      writing of the paper, wrote the majority of the text, designed the
      figures, and assisted in data gathering and analysis.
    \end{authorsContribution}
\end{publications}


\paragraph{Articles}

\begin{publications}[resume]
  \item \labelPublication{cases-paper}
    \fullcite{HjortBlindellEtAl:2017:CASES}.
    %
    \begin{authorsContribution}
      I designed and implemented the work presented in the paper, gathered and
      analyzed the experimental data, oversaw the writing of the paper, wrote
      the majority of the text, and designed the figures.
    \end{authorsContribution}
\end{publications}
%
\refTable{contributions-per-publication} shows the relation between the
contributions and the publications above.
%
Note that contribution~\refContribution{integration} only appears in this
dissertation and in none of the publications.

\begin{table}
  \centering%
  \begin{tabular}{c@{\qquad}*{11}{c}}
    \toprule
      \tabhead publication
    & \tabhead\refContribution{survey}
    & \tabhead\refContribution{representations}
    & \multicolumn{6}{c}{\tabhead\refContribution{constraint-model}}
    & \tabhead\refContribution{solving-techniques}
    & \tabhead\refContribution{experiments}
    & \tabhead\refContribution{integration}\\
    \cmidrule(lr){4-9}%
    &
    &
    & \tabhead\refContribution{cp-uniform-selection}
    & \tabhead\refContribution{cp-global-instruction-selection}
    & \tabhead\refContribution{cp-global-code-motion}
    & \tabhead\refContribution{cp-data-copying}
    & \tabhead\refContribution{cp-block-ordering}
    & \tabhead\refContribution{cp-value-reuse}
    &
    &
    &\\
    \midrule
    \refPublication{survey-book}
    & \supportYes
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo\\
    \refPublication{cp-paper}
    & \supportNo
    & \supportYes
    & \supportYes
    & \supportYes
    & \supportYes
    & \supportYes
    & \supportYes
    & \supportNo
    & \supportNo
    & \supportYes
    & \supportNo\\
    \refPublication{cases-paper}
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportNo
    & \supportYes
    & \supportYes
    & \supportYes
    & \supportNo\\
    \bottomrule
  \end{tabular}

  \caption{Contributions per publication}
  \labelTable{contributions-per-publication}
\end{table}

I also participated in the following publications, not included in the
dissertation:


\paragraph{Book Chapters, Conference Papers, and Workshop Papers}

\begin{publications}[resume]
  \item \labelPublication{survey-report}
    \fullcite{HjortBlindell:2013:Survey}.
  \item \labelPublication{scopes}
    \fullcite{CastanedaLozanoEtAl:2013:M-SCOPES}.
    %
    \begin{authorsContribution}
      I assisted in writing the paper.
    \end{authorsContribution}
  \item \labelPublication{lctes}
    \fullcite{CastanedaLozanoEtAl:2014:LCTES}.
    %
    \begin{authorsContribution}
      I assisted in gathering and analyzing the experimental data, and
      to writing the paper.
    \end{authorsContribution}
  \item \labelPublication{cc}
    \fullcite{CastanedaLozanoEtAl:2016:CC}.
    %
    \begin{authorsContribution}
      I assisted in writing the paper.
    \end{authorsContribution}
  \item \labelPublication{fdl-2016}
    \fullcite{HjortBlindellEtAl:2016:FDL}.
    %
    \begin{authorsContribution}
      I designed and implemented the work presented in the paper, gathered and
      analyzed the experimental data, oversaw the writing of the paper, wrote
      the majority of the text, and designed the figures.
    \end{authorsContribution}
\end{publications}
%
\refPublication{survey-report} is excluded as it is subsumed and extended by
\refPublication{survey-book}. \refPublication{scopes}--\refPublication{cc} are
excluded as they are only partially related to the dissertation (they apply
\glsdesc{CP} to solve \gls{register allocation} and \gls{instruction scheduling}
without considering \gls{instruction selection}). \refPublication{fdl-2016} is
excluded as it belongs to a different topic entirely (high-level code generation
for graphics processors).


\section{Research Methodology}
\labelSection{intro-research-methodology}

I begin with a comprehensive and systematic literature survey to identify the
strengths and limitations of existing \gls{instruction selection} techniques and
common denominators among them.
%
As part of this survey, four \gls{instruction selection} \glspl{principle} and
five \glspl{instruction characteristic} are identified and the techniques are
systematically classified accordingly.
%
This classification enables us to recognize that certain classes of
\glspl{instruction} are poorly supported by existing \gls{instruction selection}
techniques.
%
This is especially due to lack of appropriate \gls{program} and
\gls{instruction} representations.

Having established the need for new representations, I identify a set of
requirements that such a representation must fulfill.
%
I then build a new representation by unifying two existing, well-established
representations -- one for capturing data flow and another for capturing control
flow -- and then augment the result as needed until all requirements are met.
%
As is common, I then apply a traditional \gls{subgraph isomorphism} algorithm
for doing \gls{pattern matching} on this new representation.

With the new representation at hand, I proceed with building the \gls{constraint
  model}.
%
For each task to be integrated, I first identify what constitutes a
\gls{solution} to this task and then add the necessary \glspl{variable} and
\glspl{constraint} to enforce such \glspl{solution}.
%
If more than one design choice exists for integrating the task, then I implement
both as separate \glsplshort{constraint model} and evaluate which is better
before proceeding.
%
This is because the tasks are orthogonal from one another and can therefore be
evaluated in isolation.
%
The evaluation methodology is described in
\refSection{intro-evaluation-methodology}.

Once all tasks are integrated, I apply a range of solving techniques in order to
increase scalability and robustness.
%
Because these techniques influence one another, I first evaluate the usefulness
of each solving technique individually in order to form groups of solving
techniques and then evaluate each group as a whole.
%
This is to avoid unreasonably long experiment runtimes.

Using the \gls{constraint model} with the best design choices and solving
techniques, I then evaluate the significance of \gls{universal instruction
  selection} by comparing its \glspl{solution} with those produced by the state
of the art.


\section{Experimental Evaluation Methodology}
\labelSection{intro-evaluation-methodology}

In this section, I describe how I produce and interpret the data for the
experimental evaluation.


\subsection{Experiment Setup}

To evaluate a \gls{constraint model}, I implement it using \mbox{\gls{MiniZinc}
  2.1.6}~\cite{NethercoteEtAl:2007} -- a high-level \gls{constraint} modeling
language -- and then solve it using \gls{Chuffed}~\cite{Chu:2011} -- a
\glsdesc{LCG}-based \glsshort{constraint solver}, which is included in
\gls{MiniZinc} -- on a Linux machine with an \gls{Intel} Xeon W3530 at
\SI{2.80}{\GHz} and \SI{16}{\giga\byte} main memory.
%
To mitigate deviations in the measurments, I run each experiment ten times and
then take the arithmetic average together with the \gls{CV}.
%
When summarizing ratios, I instead take the geometric mean since this is more
appropriate in such cases~\cite{FlemingWallace:1986}.

As problem instances, I use the \glspl{function} provided by
\gls{MediaBench}~\cite{LeeEtAl:1997} -- a benchmark suite for embedded systems
-- and the \glspl{instruction} in \gls{Hexagon}~V5 -- a \gls{DSP} with a rich
\gls{instruction set}.
%
The \gls{MediaBench} suite consists of \num{6313}~\glspl{function}, which are
compiled into \gls{LLVM} \gls{IR} code -- the intermediate format used by
\gls{LLVM} -- using \mbox{\gls{LLVM} 3.8} with optimization flag~\texttt{-O3}.
%
Due to insuffiicent support in the current toolchain, I remove all
\glspl{function} that operate on non-integer data types (such as floating point
and vector data types).
%
This leaves \num{3094}~\glspl{function}, on which further filtering will be
performed as needed for the given experiment.

For all experiments in this dissertation, the remaining pool of \glspl{function}
is too large for all to be included in the experiment as that would lead to
intractable experiment runtimes.
%
I therefore draw a limited number of samples from this pool.
%
To get a diverse set of samples, I apply \gls{k-means
  clustering}~\cite{PhansalkarEtAl:2005} to divide the \glspl{function} into
twenty clusters based on three features.
%
The first feature is the application from which the \gls{function} is derived
since, intuitively, \glspl{function} from different applications should exhibit
different characteristics.
%
The second feature is the size in number of \gls{LLVM} \gls{IR}
\glspl{instruction}.
%
This is to evaluate how the \gls{constraint model} behave as the
\glspl{function} grow larger.
%
The third feature is the number of memory \glspl{instruction}.
%
This is because, due to its many \glspl{addressing mode}, the memory
\glspl{instruction} constitute a large part of the more sophisticated
\glspl{instruction} in the \gls{instruction set}).
%
Based on these features, from each cluster I then randomly select one
\gls{function}, giving a total of twenty \glspl{function}.


\subsection{Normalizing Measurements}

\newcommand{\speedupCase}[1]{\textrm{\textsc{#1}}}

When we are interested in the relative difference between the measurements, I
normalize all values to those obtained from one \glsshort{constraint model}
which has been chosen as the \gls!{baseline}.
%
In this context, the other \glsplshort{constraint model} are called the
\glspl!{subject}.

For time measurements, the most typical method for normalization is to calculate
the \gls!{speedup}, which is computed as
%
\begin{equation}
  \frac{t_b}{t_a}
  \labelEquation{speedup-normalization}
\end{equation}
%
where $t_a$ and $t_b$ denotes time measurements obtained for a given problem
instance from \gls{subject} \glsshort{constraint model}~$a$ and \gls{baseline}
\glsshort{constraint model}~$b$.
%
A value greater than $1$ means $a$ is faster than $b$, a value less than $1$
means $b$ is faster than $a$, and a value of exactly $1$ means $a$ and $b$ take
the same time to solve a given \gls{function}.

This method, however, creates problems when plotting the normalized values as
barcharts.
%
Since the normalized values are centered around $1$, when $a$ is twice as fast
as $b$ we intuitively expect the normalized value to be equally far away from
$1$ as when $b$ is twice as fast as $a$.
%
With \refEquation{speedup-normalization}, this is not the case.
%
See for example \refFigure{speedup-comparison-regular}, illustrating two
cases: \speedupCase{i}, where $a$ is twice as fast as $b$; and \speedupCase{ii},
where $b$ is twice as fast as $a$.
%
\begin{figure}
  \renewcommand{\functionName}[1]{{\Large\speedupCase{#1}}}%
  \renewcommand{\plotSpeedupTicsFont}{\large}%
  \renewcommand{\barValueFont}{\scriptsize}%

  \def\insertSpeedupExamplePlot#1{%
    \maxsizebox{30mm}{!}{%
      \trimbox{18pt 8pt 74mm 45mm}{%
        \input{figures/constraint-model/speedup-example-#1.plot}%
      }%
    }%
  }%

  \mbox{}%
  \hfill%
  \subcaptionbox{%
                  Values normalized using speedup
                  (\refEquation{speedup-normalization})%
                  \labelFigure{speedup-comparison-regular}%
                }%
                [40mm]%
                {%
                  \insertSpeedupExamplePlot{regular}%
                }%
  \hfill%
  \subcaptionbox{%
                  Values normalized using zero-centered normalization
                  (\refEquation{zero-centered-normalization})%
                  \labelFigure{speedup-comparison-zero-centered}%
                }%
                [50mm]%
                {%
                  \insertSpeedupExamplePlot{zero-centered}%
                }%
  \hfill%
  \mbox{}

  \caption[Comparison between two methods for normalizing measurements]%
          {%
            Comparison between the two methods for normalizing measurements.
            %
            The comparison is done for two problem instances: one where the
            subject is twice as fast as the baseline (\speedupCase{i}), and
            another where the baseline is twice as fast as the subject
            (\speedupCase{ii})%
          }%
  \labelFigure{speedup-comparison}%
\end{figure}
%
When plotting such values, I therefore normalize the values using a different
method, called \gls!{zero-centered normalization}, which is computed as
%
\begin{equation}
  \left\{
  \begin{array}{ll}
    \frac{t_b - t_a}{t_a} & \text{if $t_b \geq t_a$,} \\
    \frac{t_b - t_a}{t_b} & \text{otherwise.}
  \end{array}
  \right.
  \labelEquation{zero-centered-normalization}
\end{equation}
%
As seen in \refFigure{speedup-comparison-zero-centered}, this method results in
normalized values that are centered around $0$ (hence its name) and, unlike the
\gls{speedup} method, are equally far apart in the case of \speedupCase{i} and
\speedupCase{ii}.
%
A normalized value $v$ using \gls{zero-centered normalization} corresponds a
\gls{speedup} of \mbox{$v + 1$} if \mbox{$v \geq 0$}, otherwise
\mbox{$\frac{1}{1 - v}$}.

\Gls{zero-centered normalization} is also applied when comparing \gls{solution}
costs as they represent an estimate of the time it would take to execute the
code yielded by the \glspl{solution} (the current implementation is not yet able
to hook back into \gls{LLVM} in order to generate executable code).

When summarizing normalized values, however, I do not use \gls{zero-centered
  normalization} as the geometric mean cannot be computed for such values.
%
In such cases, I instead use the values normalized using the \gls{speedup}
method as the geometric mean can be computed for such values, which I call the
\gls!{GMI}.
%
A result is considered positive or negative if the \gls{GMI} is greater than
respectively less than~\num{1}.
%
In terms of solving time, for example, a \gls{subject} method~$a$ leads to an
overall reduction over another \gls{baseline} method~$b$ if the \gls{GMI} is
greater than~\num{1}.


\subsection{Attaining Statistically Significant Results}

Because I can only run experiments on a small set of \glspl{function} sampled
from much larger pool, the \gls{GMI} attained from the sampled set may not be
representative for the pool as a whole.
%
In other words, the result may not be statistically significant.

Therefore, for the \gls{GMI} value I also compute the \gls{CI}, which is a
method of estimating the uncertainty of a value computed from a set of
samples~\cite{Neyman:1937}.
%
Every \gls{CI} is computed with a predefined degree of confidence, typically
written as the $X$\textsuperscript{th} \gls{CI}.
%
This means that if the $X$\textsuperscript{th} \gls{CI} of the \gls{GMI} value
is greater than or less than~\num{1}, then we can statistically conclude with
$X\%$ confidence that the result is positive respectively negative.
%
If the \gls{CI} contains~\num{1}, then the result is inconclusive.

For the experiments described in this dissertation, I compute the
\num{95}\textsuperscript{th} \gls{CI} as is common for most statistical
experiments.
%
Since we know nothing about the underlying distributions for our observations,
I compute the \gls{CI} using \gls{percentile bootstrapping} with
\num{100000}~iterations~\cite{EfronTibshirani:1994}.


\section{Outline}
\labelSection{intro-outline}

As shown in \refFigure{dissertation-structure}, the dissertation is structured
into four parts:
%
\begin{figure}
  \centering%
  \input{figures/introduction/dissertation-structure}

  \caption{Structure of the dissertation}
  \labelFigure{dissertation-structure}
\end{figure}
%
\begin{description}
  \item[Background]
    Provides necessary background material:
    %
    \begin{inlinelist}[itemjoin={; }, itemjoin*={; and}]
      \item \refChapter{constraint-programming} describes \glsdesc{CP}, which is
        a combinatorial optimization method on which \gls{universal instruction
          selection} is based
      \item \refAppendix{graph-definitions} contains exact definitions of
        \glspl{graph} and related terms which are used throughout the
        dissertation
    \end{inlinelist}.
  \item[Literature survey]
    Discusses existing \gls{instruction selection} techniques:
    %
    \begin{inlinelist}[itemjoin={; }, itemjoin*={; and}]
      \item \refChapter{existing-isel-techniques-and-reps} covers the techniques
        relevant for \gls{universal instruction selection}
      \item \refAppendixList{macro-expansion, tree-covering, dag-covering,
        graph-covering} cover the remaining techniques
      \item \refAppendix{list-of-techniques} lists a summary of all discussed
        techniques
    \end{inlinelist}.
  \item[Universal instruction selection]
    Presents the approach:
    %
    \begin{inlinelist}[itemjoin={; }, itemjoin*={; and}]
      \item \refChapter{universal-representation} introduces the \gls{universal
        representation}
      \item \refChapter{constraint-model} introduces the \gls{constraint model}
      \item \refChapter{solving-techniques} introduces the solving techniques
      \item \refChapter{exp-evaluation-using-the-state-of-the-art} evaluates the
        approach using the state of the art
      \item \refAppendix{minizinc-implementation} provides an implementation of
        the \gls{constraint model}, written in \gls{MiniZinc}
    \end{inlinelist}.
  \item[Ending]
    Closes the dissertation:
    %
    \begin{inlinelist}[itemjoin={; }, itemjoin*={; and}]
    \item \refChapter{proposed-model-extensions} proposes
      \glsshort{constraint model} extensions
      \item \refChapter{conclusions-future-work} presents conclusions and
        future work
    \end{inlinelist}.
\end{description}
