% Copyright (c) 2017, Gabriel Hjort Blindell <ghb@kth.se>
%
% This work is licensed under a Creative Commons 4.0 International License (see
% LICENSE file or visit <http://creativecommons.org/licenses/by/4.0/> for a copy
% of the license).

\chapter{Solving Techniques}
\labelChapter{solving-techniques}

This chapter introduces the techniques applied for improving solving of the
\gls{constraint model} presented in the previous chapter.
%
\RefSection{st-model-refinements} introduces \glsshort{constraint model}
refinements to strenghten \gls{propagation}.
%
\RefSection{st-cost-bounds} introduces techniques for bounding the \gls{cost
  variable}.
%
\RefSection{st-branching-strategies} introduces \glspl{branching strategy}.
%
Sections\thinspace\refSection*{st-branching-strategies}
and~\refSection*{st-impl-constraints} introduce \gls{implied.c} respectively
\glsshort{symmetry breaking.c} and \gls{dominance breaking.c}
\glspl{constraint}.
%
\RefSection{st-presolving} introduces \gls{presolving} techniques.
%
\RefSection{st-experimental-evaluation} presents an experimental evaluation of
the above techniques.
%
Lastly, \refSection{st-summary} summarizes the chapter.

The material presented in Sects.\thinspace\refSection*{st-model-refinements},
\refSection*{st-branching-strategies}, \refSection*{st-impl-constraints},
\refSection*{st-dom-breaking-constraints}, \refSection*{st-pre-dom-matches}, and
\refSection*{st-canonical-locations} is based on ideas conceived by
Mats~Carlsson, which have then been improved by the author of this dissertation.
%
All other materials in this chapter, including the text and figures, are due
entirely to the author.


\section{Model Refinements}
\labelSection{st-model-refinements}

When introducing the \gls{constraint model} in \refChapter{constraint-model},
two parts were presented using naive implementations that are indeed correct but
give poor \gls{propagation}.
%
In this section, we fix these problems by refining the \glsshort{constraint
  model}.


\subsection{Refining the Define-Before-Use Constraint}
\labelSection{st-refining-define-before-use constraint}

When describing the \gls{constraint} that all \glspl{datum} must be
\gls{define.d}[d] before \gls{use.d}[d], a simple but naive implementation was
used (\refEquation{naive-dom-alt}).
%
First, it requires use of set~\glspl{variable},\!%
%
\footnote{%
  This is because the $\mVar{dplace}$~\glspl{variable} need to be members of the
  $\mDom$~\gls{function}, which is implemented as an array into which the
  $\mVar{oplace}$~\glspl{variable} are used as indices.%
}
%
which are expensive to use and typically results in poor \gls{propagation}.
%
Moreover, set \glspl{variable} are not supported by all \glspl{constraint
  solver}.
%
This is for example the case of \gls{Chuffed}, which is used in the experimental
setup applied in this dissertation, thus preventing us from evaluating the
impact of the naive implementation.
%
Second, many \gls{implied.c} \glspl{constraint} can be applied by introducing
the notion of in which \glspl{block} \glspl{datum} are \gls{use.d}[d].
%
We first get rid the set~\glspl{variable} by capturing the information in the
$\mDom$~\gls{function} as a dominance relation matrix
%
\begin{equation}
  \begin{bmatrix}
    \begin{array}{@{\:}c|c@{\:}}
        b_1, b_2
      & b_1, b_2 \in \mBlockSet, b_1 \in \mDom(b_2)
    \end{array}
  \end{bmatrix}
  \labelEquation{dominance-matrix}
\end{equation}
%
where each row denotes the fact that a \gls{block}~$b_1$ is \gls{dominate.b}[d]
by another \gls{block}~$b_2$.
%
Next, we introduce the \glspl{variable} needed for capturing uses of
\glspl{datum}.


\subsubsection{Variables}

The set of \glspl{variable} \mbox{$\mVar{uplace}[p] \in \mBlockSet$} models in
which \gls{block} the \gls{datum} connected to \gls{operand}~$p$ is used.
%
Note that unlike the $\mVar{dplace}$~\glspl{variable}, which are indexed using a
\gls{datum}, the $\mVar{uplace}$~\glspl{variable} are indexed using an
\gls{operand}.


\subsubsection{Constraints}

Obviously, every \gls{use.d} of \glspl{datum} must be \gls{dominate.b}[d] by its
definition.
%
Given a \glsshort{dominate.b}[ance] relation matrix~$\mDomMatrix$, this
\gls{constraint} is modeled as
%
\begin{equation}
  \mTable(\mVar{uplace}[p], \mVar{dplace}[\mVar{alt}[p]], \mDomMatrix)
  \mQuantSep
  \forall p \in \mPhiOperandCompSet.
  \labelEquation{refined-dom}
\end{equation}
%
where \mbox{$\mPhiOperandCompSet \subseteq \mOperandSet$} denotes the set of
\glspl{operand} not appearing in any \gls{phi-match}.
%
We exclude such \glspl{operand} for the same reasons \glspl{phi-match} are
excluded in \refEquation{naive-dom}.

Next, if a \gls{match}~$m$ is selected and placed in \gls{block}~$b$, then all
\gls{use.d}[s] of \glspl{datum} made by $m$ should also occur in~$b$.
%
This is modeled as
%
\begin{equation}
  \begin{array}{c}
    \mVar{sel}[m] \mImp \mVar{oplace}[o] = \mVar{uplace}[p] \\
    \forall m \in \mPhiMatchCompSet,
    \forall o \in \mCovers(m),
    \forall p \in \mUses(m).
  \end{array}
  \labelEquation{refined-dom-selected}
\end{equation}
%
An example illustrating the interaction between \refEquation{refined-dom} and
\refEquation{refined-dom-selected} is shown in \refFigure{refined-dom-example}.

\begin{figure}
  \centering%
  \input{figures/solving-techniques/dom-example}%

  \caption[Example illustrating the refined define-before-use constraint]%
          {%
            Example illustrating the refined define-before-use constraint.
            %
            The assignments on the right-hand side show how these
            variables should be set if the two matches~$m_1$ and~$m_2$ are
            placed in blocks~$b_1$ respectively $b_2$, where $b_1$ is assumed to
            dominate~$b_2$%
          }
  \labelFigure{refined-dom-example}
\end{figure}

Due to \refEquation{refined-dom-selected}, the assignment to the
$\mVar{uplace}$~\glspl{variable} for non-selected \glspl{match} does not matter
as long as \refEquation{refined-dom} is satisfied, which gives rise to symmetric
\glspl{solution}.
%
To break these symmetries, we fix the assignments in such cases to the
\gls{block} wherein the \gls{datum} is \gls{define.d}[d] since a \gls{block}
always \gls{dominate.b}[s] itself.
%
This is modeled as
%
\begin{equation}
  \begin{array}{c}
    \neg\mVar{sel}[m] \mImp \mVar{uplace}[p] = \mVar{dplace}[\mVar{alt}[p]] \\
    \forall m \in \mPhiMatchCompSet,
    \forall p \in \mUses(m).
  \end{array}
  \labelEquation{refined-dom-not-selected}
\end{equation}

Since neither of the above \glspl{constraint} apply to \glspl{operand} belonging
to \glspl{phi-match}, the assignment to their $\mVar{uplace}$~\glspl{variable}
does not matter, again giving rise to symmetric \glspl{solution}.
%
We therefore fix the assignment in such cases, which is modeled as
%
\begin{equation}
  \mVar{uplace}[p] = \mMin(\mBlockSet)
  \mQuantSep
  \forall p \in \mPhiOperandSet.
  \labelEquation{refined-dom-phi-operands}
\end{equation}


\subsection{Refining the Objective Function}
\labelSection{st-refined-objective-function}

The straightforward implementation of the \gls{objective function}
(\refEquation{naive-objective-function}) is naive because it fails to reason on
how cost is distributed across the \glspl{operation} that need to be covered,
which in turn results in poor \gls{propagation}.
%
\begin{figure}
  \mbox{}%
  \hfill%
  \subcaptionbox{UF graph\labelFigure{cost-example-graph}}%
                {%
                  \input{figures/solving-techniques/cost-example-graph}%
                }%
  \hfill%
  \subcaptionbox{Cost matrix\labelFigure{cost-example-matrix}}%
                {%
                  \figureFontSize%
                  \begin{minipage}{50mm}%
                    \centering%
                    \begin{displaymath}
                      \begin{adjblockarray}{cccccc}{1ex}
                          \text{\tabhead op}
                        & \text{\tabhead match}
                        & \text{\tabhead block}
                        & \multicolumn{3}{c}{%
                            \text{%
                              \parbox{20.5mm}{%
                                % The parbox is used to create a bit of space
                                % between the content and the right bracket
                                \centering\tabhead opcost%
                              }%
                            }%
                          } \\[-.5ex]
                        \begin{block}{[cccc@{\;\times\;}c@{\;=\;}c]}
                          \rule{0pt}{2.5ex}
                          o_1 & m_1 & b_1 & 4 & 10 & 40 \\
                          o_1 & m_1 & b_2 & 4 &  1 &  4 \\
                          o_1 & m_3 & b_1 & 3 & 10 & 30 \\
                          o_1 & m_3 & b_2 & 3 &  1 &  3 \\
                          o_2 & m_2 & b_1 & 1 & 10 & 10 \\
                          o_2 & m_2 & b_2 & 1 &  1 &  1 \\
                          o_2 & m_3 & b_1 & 2 & 10 & 20 \\
                          o_2 & m_3 & b_2 & 2 &  1 &  2 \\[.55ex]
                        \end{block}
                      \end{adjblockarray}
                    \end{displaymath}
                  \end{minipage}%
                }%
  \hfill%
  \mbox{}

  \caption[Example illustrating match cost distributed over operations]%
          {%
            Example illustrating match cost distributed over operations.
            %
            It is assumed that matches~$m_1$, $m_2$, and~$m_3$ have costs~4,
            1, and~5, respectively, and that they can be placed in one of two
            blocks, $b_1$ and $b_2$, with execution frequencies~10 and~1,
            respectively.
            %
            The cost of $m_3$ distributed over $o_1$ and $o_2$ is~3 and~2,
            respectively%
          }
  \labelFigure{cost-example}
\end{figure}
%
See for example \refFigure{cost-example}.
%
Assume a \gls{UF graph} that can be covered by three \glspl{match} -- $m_1$,
$m_2$, and~$m_3$ -- which have costs~4, 1, and~5, respectively, and that they
can be placed in one of two blocks, $b_1$ and $b_2$, with execution
frequencies~10 and~1, respectively (\refFigure{cost-example-graph}).
%
Because \refEquation{naive-objective-function} is modeled as a summation, it can
only propagate the bounds of the \gls{cost variable}.
%
Consequently, for any \glspl{match} where their $\mVar{sel}$~\gls{variable} have
yet to be decided, either all those \glspl{match} are selected and placed in the
\gls{block} with highest execution frequency, or none are selected.
%
In the example above, this means the \gls{cost variable} is initially bounded as
\mbox{$0 < \mVar{cost} < 100$}, which are very weak bounds as we know that the
\gls{UF graph} must at least be covered at a cost of~5 (either both $m_1$ and
$m_2$ are selected and placed in $b_2$, or $m_3$ is selected and placed in
$b_2$) and can at most be covered at a cost of~50 (the selected \glspl{match}
are placed in $b_1$).

Instead of reasoning about the cost incurred by the \glspl{match} -- which may
or may not be selected -- a better approach is to infer the cost incurred on the
\glspl{operation} since these must always be covered.
%
The idea is as follows.
%
First, for each \gls{match}~$m$, evenly divide the cost of $m$ over each
\gls{operation}~$o$ covered by $m$.
%
If a strict partial order $<$ exists over the set of \glspl{operation}, and
$\mCovers(m)$ returns an ordered, 1-indexed list for which \mbox{$o_1 < o_2 <
  \cdots < o_k$} holds, then the cost can be divided as follows.
%
Given a match~$m$, if \mbox{$q = \lfloor \mCost(m) / \mCard{\!\mCovers(m)}
  \rfloor$} and \mbox{$r = \mCost(m) \! \mod \mCard{\!\mCovers(m)}$}, then
%
\begin{equation}
  \mOpCost(m, o) =
  \left\{
  \begin{array}{ll}
    q + 1 & \text{if $o < \mCovers(m)[r+1]$}, \\
    q     & \text{otherwise}. \\
  \end{array}
  \right.
  \labelEquation{op-cost-function}
\end{equation}
%
Then, for each \gls{block}~$b$, weigh \mbox{$\mOpCost(m, o)$} with the execution
frequency of~$b$.
%
This information can be represented as a cost matrix
%
\begin{equation}
  \begin{bmatrix}
    \begin{array}{@{\:}c|c@{\:}}
        o, m, b, \big( \mOpCost(m, o) \times \mFreq(b) \big)
      & m \in \mMatchSet, o \in \mCovers(m), b \in \mBlockSet
    \end{array}
  \end{bmatrix}
  \labelEquation{cost-matrix}
\end{equation}
where each row denotes the cost of an \gls{operation}~$o$ if covered by a
\gls{match}~$m$ and placed in a \gls{block}~$b$.
%
An example of this cost matrix is given in \refFigure{cost-example}, from which
we can deduce that the cost of covering operations~$o_1$ and~$o_2$ is between~3
and~40 respectively between~1 and~20 (\refFigure{cost-example-matrix}).
%
Hence the total cost can be bounded as \mbox{$4 < \mVar{cost} < 60$}, which is a
much tighter bound compared to that achieved using the naive \gls{objective
  function}.
%
This in turn has a tremendous impact on solving time, for reasons that will
become clear in \refSection{st-cost-bounds}.

Instead of first evenly dividing the \gls{match} cost over the covered
\glspl{operation} and then multiplying each \gls{operation} cost with the
execution frequency, an alternative method is to first multiply the \gls{match}
cost with the execution frequency and then evenly divide the product over the
covered \glspl{operation}.
%
We call the first method the \gls!{divide-then-multiply method}, and the second
method the \gls!{multiply-then-divide method}.
%
At first glace this design decision would appear to make no difference, but as
will be seen later in the experimental evaluation, they unexpectedly exhibit
significantly different solving time characteristics.
%
One possible explanation is that they may yield different bounds.
%
For instance, for the example given in \refFigure{cost-example} the
\gls{multiply-then-divide method} bounds the total cost as \mbox{$4 <
  \mVar{cost} < 65$}, whereas the \gls{divide-then-multiply method} bounds it to
\mbox{$4 < \mVar{cost} < 60$}.
%
Another possible explanation is that the \gls{divide-then-multiply method}
results in \gls{operation} costs that are even multiples of the execution
frequencies, whereas the \gls{multiply-then-divide method} potentially results
in arbitrary cost values and consequently leads to larger \glspl{domain} for the
\gls{cost variable}.


\subsubsection{Variables}

The set of \glspl{variable} \mbox{$\mVar{ocost}[o] \in \mNatNumSet$} models the
cost incurred by covering \gls{operation}~$o$\hspace{-.8pt}.
%
It is assumed the \gls{domain} is the same as for the \gls{cost variable}.


\subsubsection{Constraints}

For each \gls{operation}~$o$\hspace{-.8pt}, the combination
\mbox{$o\hspace{-.8pt}, \mVar{omatch}[o], \mVar{oplace}[o], \mVar{ocost}[o]$}
must appear as a row in the cost matrix.
%
Hence, given a cost matrix~$\mCostMatrix$ this \gls{constraint} is modeled as
%
\begin{equation}
  \mTable(
    o\hspace{-1pt},
    \mVar{omatch}[o],
    \mVar{oplace}[o],
    \mVar{ocost}[o],
    \mCostMatrix
  )
  \mQuantSep
  \forall o \in \mOpSet \hspace{-.8pt}.
  \labelEquation{omatch-oplace-ocost-connection}
\end{equation}
%
The total cost is then modeled as
%
\begin{equation}
  \mVar{cost} = \sum_{o \in \mOpSet} \mVar{ocost}[o].
  \labelEquation{total-cost}
\end{equation}


\section{Tightening the Cost Bounds}
\labelSection{st-cost-bounds}

As explained in \refChapter{constraint-programming}, in \gls{CP} optimization
problems are solved using \gls{branch and bound}.
%
In other words, when a \gls{solution} is found a \gls{constraint} is added to
the \glsshort{constraint model}, forcing any subsequently found \glspl{solution}
to be strictly better.
%
This means that if a part of the \gls{search space} is known not to contain any
better \glspl{solution} -- this is achieved by checking the current lower bound
of the \gls{cost variable} -- then this part need not be explored during
\gls{search}.
%
For this to be effective, however, it must be possible to infer reasonable
bounds on the \gls{cost variable}, which asserts the need for the refined
\gls{objective function} introduced in
\refSection{st-refined-objective-function}.

By the same mechanism, solving can improved by tightening the lower and upper
bounds of the \gls{cost variable} before commencing \gls{search}.
%
A tight upper bound helps the \gls{constraint solver} to prune away parts of the
\gls{search space} that contains inferior \glspl{solution}, while a tight lower
bound helps the \gls{constraint solver} to prune away parts of the \gls{search
  space} that contains no \glspl{solution}.
%
A decent upper bound can be computed by solving the same problem using a greedy
but fast heuristic.
%
To this end, any modern \gls{compiler} can be used.
%
A decent lower bound be computed by solving a relaxed version of the
\gls{constraint model} that only models the \gls{global.is} \gls{instruction
  selection} and \gls{block ordering} problems, which obviously is simpler to
solve than the complete \glsshort{constraint model}.
%
Hence, the relaxed \glsshort{constraint model} consists of only the
$\mVar{omatch}$, $\mVar{opcosts}$, $\mVar{sel}$, $\mVar{succ}$, and
$\mVar{cost}$ variables, \refEquation{operation-coverage}, relaxed versions of
Eqs.\thinspace\refEquation*{block-order} and \refEquation*{fall-through} that
allow fall-throughs via non-empty \glspl{block}, and modified versions of
Eqs.\thinspace\refEquation*{cost-matrix}--\refEquation*{total-cost} that do not
take the execution frequencies into account.

If $\mRelaxedCost$ and $\mHeuristicCost$ denote the cost computed from the
relaxation and by the heuristic, respectively, then the \gls{cost variable} is
bounded as
%
\begin{equation}
  \mRelaxedCost \leq \mVar{cost} < \mHeuristicCost.
  \labelEquation{lower-bound}
\end{equation}


\section{Branching Strategies}
\labelSection{st-branching-strategies}

As explained in \refChapter{constraint-programming}, the \gls{branching
  strategy} decides how to explore the \gls{search space}.
%
In optimization problems, it is generally a good approach to try to find the
optimal \gls{solution} first as that will allow pruning of the still unexplored
parts of the \gls{search space}.
%
To this end, we first branch on the $\mVar{ocost}$~\glspl{variable}, selecting
the \gls{variable}~$v$ with the maximum \gls!{regret} -- that is, the
\gls{variable} with the largest difference between the two smallest values in
its \gls{domain} -- and the smallest value in the \gls{domain} of~$v$.
%
The intuition here is that, because our \gls{objective function} strives to
minimize the total cost, we wish to minimize the cost incurred per
\gls{operation}.
%
By selecting the \gls{variable} with the maximum \gls{regret}, we try to cover
the \glspl{operation} for which to cost of bad decisions is largest, and for
these we obviously try to cover these at least cost.
%
Note that this \gls{branching strategy} is only possible due to the refined
\gls{objective function} described earlier in this chapter.

Remaining decisions are left to the \gls{constraint solver}.
%
To improve \gls{match} selection, however, we make sure to arrange them in
order of increasing latency.
%
If there is a tie between two \glspl{match}, and either of them is a \gls{kill
  match}, then the \gls{kill match} comes first.
%
Otherwise, the \gls{match} covering more \glspl{operation} comes first (hence
mimicking the scheme of \gls{maximum munch}).
%
This is because the \gls{constraint solver} will most likely attempt to select
\glspl{match} in the order given to the \glsshort{constraint model}.
%
In such a setting, it is generally a good approach to first try a \gls{kill
  match}, which incurs no cost and encourages value reuse, and then the
\gls{match} which incurs the least cost.


\section{Implied Constraints}
\labelSection{st-impl-constraints}

As explained in \refChapter{constraint-programming}, \gls{implied.c}
\glspl{constraint} are \glspl{constraint} that strengthen the \gls{propagation}
while preserving all \glspl{solution}.
%
Stronger \gls{propagation} leads to less \gls{search}, which in turn leads to
shorter solving times.
%
In this section, we discuss such \glspl{constraint} that have been added to the
\glsshort{constraint model}.


\subsubsection{Implied Operation and Data Placements}

Due to \refEquationRange{naive-dom}{spanning}, if a selected \gls{match}
\gls{define.d}[s] some \gls{datum}~$d_1$ and \gls{use.d}[s] some other
\gls{datum}~$d_2$, then the \gls{block} wherein $d_2$ is \gls{define.d}[d] must
\gls{dominate.b} the \gls{block} wherein $d_1$ is \gls{define.d}[d].
%
From this observation, we can infer that if all \glspl{match} covering a
non-\gls{phi-node} \gls{operation}~$o$ do not \gls{span.b} any \glspl{block},
\gls{define.d} some \gls{datum}~$d_1$, and \gls{use.d} some \gls{datum}~$d_2$,
then the \gls{block} wherein $d_2$ is \gls{define.d}[d] must \gls{dominate.b}
the \gls{block} wherein $d_1$ is \gls{define.d}[d].
%
In addition, $o$ must be placed in the same \gls{block} wherein $d_1$ is
\gls{define.d}[d].
%
This is modeled as
%
\begin{equation}
  \begin{array}{c}
    \mTable(\mVar{dplace}[d_1], \mVar{dplace}[d_2], \mDomMatrix)
    \mAnd
    \mVar{oplace}[o] = \mVar{dplace}[d_1] \\
    \forall o \in
      \mSetBuilder{o'}%
                  {%
                    o' \in \mOpCompSet{\mPhi},
                    m \in \mMatchSet[o'] \hspace{-1pt}
                    \text{ \st }
                    \mConsumes(m) = \mEmptySet
                  }, \\
    \forall d_1 \in
      \mSetBuilder{d}%
                  {%
                    d \in \mDataOf(o \hspace{-1pt}, \mDefines),
                    m \in \mMatchSet[o] \hspace{-1pt},
                    \exists p \in \mDefines(m)
                    \text{ \st }
                    \mDataSet[p] = \mSet{d}
                  }, \\
    \forall d_2 \in
      \mSetBuilder{d}%
                  {%
                    d \in \mDataOf(o \hspace{-1pt}, \mUses),
                    m \in \mMatchSet[o] \hspace{-1pt},
                    \exists p \in \mUses(m)
                    \text{ \st }
                    \mDataSet[p] = \mSet{d}
                  }.
  \end{array}
  \labelEquation{impl-cons-defs-dominate-defs}
\end{equation}
%
where
%
\begin{equation}
  \mDataOf(o \hspace{-1pt}, f)
  \equiv
  \hspace{-1.5em}
  \bigcup_{\substack{%
                   m \, \in \, \mMatchSet[o] \hspace{-.8pt}, \\
                   p \, \in \, f\hspace{-1pt}(m) \text{ \st} \\
                   \mCovers(m) \, = \, \mSet{o}
                 }}
  \hspace{-1.5em}
  \mDataSet[p]
  \labelEquation{data-of-function}
\end{equation}

Furthermore, we can infer that if all \glspl{match} covering the same
non-\gls{phi-node} \gls{operation} \gls{span.b} a set~$S$ of \glspl{block} and
\gls{define.d} some \gls{datum}~$d$\hspace{-1pt}, then $d$ must be
\gls{define.d}[d] in one of the \glspl{block} in~$S$\hspace{-.8pt}.
%
This is modeled as
%
\begin{equation}
  \begin{array}{c}
    \mVar{dplace}[d] \in S \\
    \forall S \in \mPowerset{\mBlockSet} \hspace{-2pt},
    \forall d \in \mDataSet \!,
    \forall o \in
      \mSetBuilder*{o'}%
                   {%
                     \begin{array}{@{}l@{}}
                       o' \in \mOpCompSet{\mPhi},
                       m \in \mMatchSet[o'] \hspace{-1pt},
                       \exists p \in \mDefines(m) \\
                       \text{\st }
                       \mSpans(m) = S \mAnd \mDataSet[p] = \mSet{d}
                     \end{array}
                   } \!.
  \end{array}
  \labelEquation{impl-cons-defs-in-spanned-blocks}
\end{equation}

From \refEquation{preventing-control-flow-op-moves}, we can infer that if all
non-\glspl{phi-match} covering \gls{operation}~$o$ have \gls{entry
  block}~$b$\hspace{-1pt}, then $o$ must for sure be placed in~$b$\hspace{-1pt}.
%
This is modeled as
%
\begin{equation}
  \begin{array}{c}
    \mVar{oplace}[o] = b \\
    \forall b \in \mBlockSet \hspace{-1pt},
    \forall o \in
      \mSetBuilder{o'}%
                  {%
                    o' \in \mOpSet,
                    m \in \mMatchSet[o'] \setminus \mPhiMatchSet
                    \text{ \st }
                    \mEntry(m) = \mSet{b}
                  }.
  \end{array}
  \labelEquation{impl-cons-identical-entry-blocks}
\end{equation}

Furthermore, we can infer that if the \glspl{match} covering the same
non-\gls{phi-node} \gls{operation} all have identical \glspl{entry block}, say
$b$\hspace{-1pt}, and make \gls{use.d} of some \gls{datum}~$d$\hspace{-1pt},
then the \gls{block} wherein $d$ is \gls{define.d}[d] must dominate
$b$\hspace{-1pt}.
%
This is modeled as
%
\begin{equation}
  \begin{array}{c}
    \mTable(b \hspace{-.8pt}, \mVar{dplace}[d], \mDomMatrix) \\
    \forall b \in \mBlockSet \hspace{-1pt},
    \forall d \in
      \mSetBuilder*{d'}%
                   {%
                     \begin{array}{@{}l@{}}
                       o' \in \mOpCompSet{\mPhi},
                       m \in \mMatchSet[d'] \hspace{-1pt},
                       \exists p \in \mUses(m) \\
                       \text{ \st}
                       \mEntry(m) = \mSet{b} \mAnd \mDataSet[p] = \mSet{d}
                     \end{array}
                   } \!.
  \end{array}
  \labelEquation{impl-cons-defs-dominate-entry-blocks}
\end{equation}

From \refEquation{def-edges}, we can infer that if a \gls{datum}~$d$ appears in
a \gls{definition edge}~$\mEdge{b}{d}$ and is \gls{define.d}[d] by
\glspl{phi-match} only, then the \gls{operation} covered by these \glspl{match}
must be placed $b$.
%
This is modeled as
%
\begin{equation}
  \begin{array}{c}
    \mVar{oplace}[o] = b \\
    \forall \mEdge{d}{b} \in \mFunctionDefEdgeSet,
    \forall o \in
      \mSetBuilder{o'}%
                  {%
                    \begin{array}{@{}l@{}}
                      m \in \mMatchSet[d] \cap \mPhiMatchSet,
                      o' \in \mCovers(m)
                    \end{array}
                  }.
  \end{array}
  \labelEquation{impl-cons-place-phi-ops-same-as-def-edges}
\end{equation}
%
It is assumed that the \glspl{edge} in $\mFunctionDefEdgeSet$ have been
reoriented such that all \glspl{source} are either \glsshort{state node} or
\glspl{value node} and all \glspl{target} are \glspl{block node}.


\subsubsection{%
  Implied Constraints due to the Define-Before-Use Refinement%
}

From \refEquationRange{refined-dom}{refined-dom-phi-operands}, we can infer the
following \gls{implied.c} \glspl{constraint}.

If a non-\gls{phi-match} that \gls{span.b}[s] no \glspl{block} is selected, then
all \glspl{datum} it \gls{use.d}[s] and \gls{define.d}[s] must take place in the
same \gls{block}.
%
This is modeled as
%
\begin{equation}
  \begin{array}{c}
    \mVar{sel}[m] \mImp \mVar{uplace}[p_1] = \mVar{uplace}[p_2] \\
    \forall m \in
      \mSetBuilder{m'}%
                  {%
                    m \in \mPhiMatchCompSet \hspace{-1pt},
                    \mSpans(m) = \mEmptySet
                  },
    \forall p_1, p_2 \in \mUses(m) \\
    \text{\st } p_1 < p_2,
  \end{array}
  \labelEquation{impl-cons-no-span-uses}
\end{equation}
%
\begin{equation}
  \begin{array}{c}
    \mVar{sel}[m]
    \mImp
    \mVar{dplace}[\mVar{alt}[p_1]] = \mVar{dplace}[\mVar{alt}[p_2]] \\
    \forall m \in
      \mSetBuilder{m'}%
                  {%
                    m \in \mPhiMatchCompSet \hspace{-1pt},
                    \mSpans(m) = \mEmptySet
                  },
    \forall p_1, p_2 \in \mDefines(m) \text{ \st } p_1 < p_2,
  \end{array}
  \labelEquation{impl-cons-no-span-defs}
\end{equation}
%
\begin{equation}
  \begin{array}{c}
    \mVar{sel}[m]
    \mImp
    \mVar{uplace}[p_1] = \mVar{dplace}[\mVar{alt}[p_2]] \\
    \forall m \in
      \mSetBuilder{m'}%
                  {%
                    m \in \mPhiMatchCompSet \hspace{-1pt},
                    \mSpans(m) = \mEmptySet
                  }, \\
    \forall p_1 \in \mUses(m) \setminus \mDefines(m),
    \forall p_2 \in \mDefines(m).
  \end{array}
  \labelEquation{impl-cons-no-span-use-defs}
\end{equation}

If a non-\gls{phi-match} \gls{span.b}[ning] some \glspl{block} is selected, then
all \gls{use.d}[s] of the input \glspl{datum} must occur in the same
\gls{block}.
%
This is modeled as
%
\begin{equation}
  \begin{array}{c}
    \mVar{sel}[m] \mImp \mVar{uplace}[p_1] = \mVar{uplace}[p_2] \\
    \forall m \in
      \mSetBuilder{m'}%
                  {%
                    m \in \mPhiMatchCompSet \hspace{-1pt},
                    \mSpans(m) \neq \mEmptySet
                  },
    \forall p_1, p_2 \in \mUses(m) \setminus \mDefines(m) \\
    \text{\st } p_1 < p_2.
  \end{array}
  \labelEquation{impl-cons-spanned-input}
\end{equation}


\subsubsection{Implied Data Locations}

Several \gls{implied.c} \glspl{constraint} can be due to
\refEquation{compatible-locations}.

If all non-\glspl{kill match} covering some \gls{operation} require some
non-\glsshort{state node} \gls{datum}~$d$ as input, then $d$ cannot be an
intermediate value nor be \gls{killed.d}.
%
Such \glspl{datum} is said to be \gls!{available.d}, meaning they cannot be
located in either $\mIntLocation$ or $\mKilledLocation$.
%
If the input can be one of several values (due to \glspl{alternative value}),
then at least one of those values must be made \gls{available.d}.
%
This is modeled as
%
\begin{equation}
  \begin{array}{c}
    \exists d \in S,
    \mVar{loc}[d] \notin \mSet{\mIntLocation, \mKilledLocation} \\
    \forall S \in \mPowerset{\mStateDataCompSet} \hspace{-2pt},
    \forall o \in
      \mSetBuilder*{o'}%
                   {%
                     \begin{array}{@{}l@{}}
                       o' \in \mOpSet \!,
                       m \in \mMatchSet[o'] \hspace{-1pt},
                       \exists p \in \mUses(m) \setminus \mDefines(m) \\
                       \text{\st }
                       \mDataSet[p] = S
                     \end{array}
                   } \!.
  \end{array}
  \labelEquation{impl-cons-used-data-must-be-available}
\end{equation}
%
where $\mStateDataCompSet$ denotes the set of \glspl{datum} without the
\glspl{state node}.

If all non-\glspl{kill match} defining a non-\glsshort{state node}
\gls{datum}~$d$ have $d$ as an \gls{exterior value}, then $d$ must be made
\gls{available.d}.
%
This is modeled as
%
\begin{equation}
  \begin{array}{c}
    \mVar{loc}[d] \notin \mSet{\mIntLocation, \mKilledLocation} \\
    \forall d \in
      \mSetBuilder*{d'}%
                   {%
                     \begin{array}{@{}l@{}}
                       d' \in \mStateDataCompSet,
                       m \in \mMatchSet[d'] \setminus \mKillMatchSet,
                       \exists p \in \mDefines(m) \text{ \st} \\
                       \mDataSet[p] = \mSet{d'}
                       \mAnd
                       \mIsExt(m, p)
                     \end{array}
                   } \!.
  \end{array}
  \labelEquation{impl-cons-exterior-data-must-be-available}
\end{equation}
%
where \mbox{$\mIsExt(m, p)$} denotes whether an \gls{operand}~$p$ in a
\gls{match}~$m$ represents an \gls{exterior value}.

We can always constrain the \glspl{location} of a non-\glsshort{state node}
\gls{datum}~$d$ to those \glspl{location} where the definers can put $d$.
%
The intuition here is to take the union of all those \glspl{location}, which is
modeled as
%
\begin{equation}
  \begin{array}{c}
    \mVar{loc}[d] = S \\
    \forall d \in \mStateDataCompSet,
    \forall S \in
      \mPowerset{\mLocationSet
      \, \cup \,
      \mSet{\mIntLocation, \mKilledLocation}} \text{ \st} \\
    S = \mSetBuilder{l}%
                    {%
                      m \in \mDataSet[d] \setminus \mKillMatchSet,
                      p \in \mDefines(m),
                      l \in \mStores(m, p)
                      \text{ \st }
                      d \in \mDataSet[p]
                    },
  \end{array}
  \labelEquation{impl-cons-locs-of-uses}
\end{equation}

Likewise, we can always constrain the \glspl{location} of a non-\glsshort{state
  node} \gls{datum}~$d$ to those \glspl{location} where the users can access $d$
(assuming there is always at least one \gls{match} making use of $d$).
%
This is modeled similarly as
%
\begin{equation}
  \begin{array}{c}
    \mVar{loc}[d] = S \\
    \forall d \in \mStateDataCompSet,
    \forall S \in
      \mPowerset{\mLocationSet
      \, \cup \,
      \mSet{\mIntLocation, \mKilledLocation}} \text{ \st} \\
    S = \mSetBuilder{l}%
                    {%
                      m \in \mKillMatchCompSet,
                      p \in \mUses(m),
                      l \in \mStores(m, p)
                      \text{ \st }
                      d \in \mDataSet[p]
                    }
    \mAnd
    S \neq \mEmptySet.
  \end{array}
  \labelEquation{impl-cons-locs-of-defs}
\end{equation}


\subsubsection{Implied Fall-Through}

Due to \refEquation{fall-through}, if for any two \glspl{block}~$b_1$ and~$b_2$
there exists a \gls{match} requiring $b_2$ to follow $b_1$ but none requiring
any other \gls{block} to follow $b_1$ nor $b_2$ to follow any other \gls{block},
then it is always safe to force $b_2$ to follow $b_1$.
%
This is modeled as
%
\begin{equation}
  \begin{array}{c}
    \mVar{succ}[b_1] = b_2 \\
    \forall b_1, b_2 \in \mBlockSet
    \text{ \st }
    \mSetBuilder{\mEntry(m)}{\mPair{m}{b_2} \in \mFallThroughSet} = \mSet{b_1}
    \mAnd \mbox{} \\
    \mSetBuilder{b}%
                {%
                  \mPair{m}{b} \in \mFallThroughSet
                  \text{ \st }
                  \mEntry(m) = \mSet{b_1}%
                } = \mSet{b_2}.
  \end{array}
  \labelEquation{impl-cons-fix-fall-throughs}
\end{equation}


\section{Symmetry and Dominance Breaking Constraints}
\labelSection{st-dom-breaking-constraints}

As explained in \refChapter{constraint-programming}, \glsshort{symmetry
  breaking.c} and \gls{dominance breaking.c} \glspl{constraint} are
\glspl{constraint} that remove \glspl{solution} from the \gls{search space} that
are either symmetric to one another or dominated by some other \gls{solution}.
%
Since this leads to a smaller \gls{search space}, the solving time is reduced.
%
In this section, we discuss such \glspl{constraint} that have been added to the
\glsshort{constraint model}.


\subsubsection{Location of State Nodes}

Since \glspl{datum} also includes the \glspl{state node}, this means a
$\mVar{loc}$~\gls{variable} will be allocated for each individual \gls{state
  node}.
%
However, since \glspl{state node} are abstract entities used only to capture
implicit dependencies between certain \gls{operation}, the assignment to these
\glspl{variable} has no actual bearing on the \gls{solution}, thus giving rise
to many symmetric \glspl{solution}.
%
Consequently, it makes sense to fix the \gls{location} for each \gls{state
  node}, which is modeled as
%
\begin{equation}
  \mVar{loc}[d] = \mIntLocation
  \mQuantSep
  \forall d \in \mStateDataSet,
  \labelEquation{dom-cons-locs-of-states}
\end{equation}
%
where \mbox{$\mStateDataSet \subseteq \mDataSet$} denotes the set of
\glspl{state node}.


\subsubsection{Operands of Non-Selected Matches}

The $\mVar{alt}$~\glspl{variable} of \glspl{match} that are not selected still
need to be assigned a value.
%
Since this assignment does not matter for the \gls{solution}, it gives rise to
many symmetric \glspl{solution}.
%
We therefore fix the $\mVar{alt}$ assignments in such cases, which is modeled as
%
\begin{equation}
  \begin{array}{c}
    \neg\mVar{sel}[m] \mImp \mVar{alt}[p] = \mMin(\mDataSet[\hspace{-1pt}p]) \\
    \forall m \in \mMatchSet,
    \forall p \in \mDefines(m) \cup \mUses(m).
  \end{array}
  \labelEquation{dom-cons-operands-of-non-selected-matches}
\end{equation}

The \gls{symmetry breaking.c} \gls{constraint} above also implies that if an
\gls{operand} representing input with multiple \glspl{datum} does not take its
minimum value, then the corresponding \gls{match} must be selected, which means
that the corresponding \gls{datum} must be in a usable \gls{location}.
%
This is modeled as
\begin{equation}
  \begin{array}{c}
    \mVar{alt}[p] \neq \mMin(\mDataSet[p])
    \mImp
    \mVar{alt}[p] \notin \mSet{\mIntLocation, \mKilledLocation} \\
    \forall m \in \mMatchSet,
    \forall p \in \mUses(m) \setminus \mDefines(m)
    \text{ \st }
    \mCard{\mDataSet[p]} > 1.
  \end{array}
  \labelEquation{impl-cons-input-operands-not-taking-min-value}
\end{equation}


\subsubsection{Interchangeable Data}

As described in \refSection{modeling-value-reuse}, \glspl{datum} in the \gls{UF
  graph} that are copies of the same value are \gls{copy-related.d} and
therefore interchangeable.
%
\begin{figure}
  \begin{minipage}[b]{58mm}%
    \centering%
    \subcaptionbox{%
                    UF graph, where the values \irVar{v}[1] and \irVar{v}[2]
                    constitute a chain of interchangeable data%
                    \labelFigure{interchangeable-data-example-annotated-graph}%
                  }%
                  [\textwidth]%
                  {%
                    \input{%
                      figures/solving-techniques/%
                      interchangeable-data-example-annotated-graph%
                    }%
                  }

    \vspace{\betweensubfigures}

    \subcaptionbox{%
                    Symmetries due to how data can be connected to operands%
                    \labelFigure{interchangeable-data-example-alt-solutions}%
                  }%
                  [\textwidth]%
                  {%
                    \input{%
                      figures/solving-techniques/%
                      interchangeable-data-example-alt-1%
                    }%
                    \hspace{8mm}%
                    \input{%
                      figures/solving-techniques/%
                      interchangeable-data-example-alt-2%
                    }%
                  }%
  \end{minipage}%
  \hfill%
  \begin{minipage}[b]{58mm}%
    \centering%
    \subcaptionbox{%
                    Symmetries due to how null-copy matches can be selected%
                    \labelFigure{interchangeable-data-example-null-solutions}%
                  }%
                  [\textwidth]%
                  {%
                    \input{%
                      figures/solving-techniques/%
                      interchangeable-data-example-null-1%
                    }%
                    \hspace{8mm}%
                    \input{%
                      figures/solving-techniques/%
                      interchangeable-data-example-null-2%
                    }%
                  }

    \vspace{\betweensubfigures}

    \subcaptionbox{%
                    Symmetries due to how kill matches can be selected%
                    \labelFigure{interchangeable-data-example-kill-solutions}%
                  }%
                  [\textwidth]%
                  {%
                    \input{%
                      figures/solving-techniques/%
                      interchangeable-data-example-kill-1%
                    }%
                    \hspace{8mm}%
                    \input{%
                      figures/solving-techniques/%
                      interchangeable-data-example-kill-2%
                    }%
                  }%
  \end{minipage}

  \caption[Example of interchangeable data]%
          {%
            Example of interchangeable data and how these give rise to
            symmetries%
          }
  \labelFigure{interchangeable-data-example}
\end{figure}
%
This is another source for symmetric \glspl{solution}, which is illustrated in
\refFigure{interchangeable-data-example}.

Assume a \gls{UF graph} containing two \gls{copy-related.d} values, \irVar{v}[1]
and~\irVar{v}[2], that may both be connected to two \glspl{operand}~$p_1$
and~$p_2$ (\refFigure{interchangeable-data-example-annotated-graph}).
%
We say that a set of values constitute a chain of \gls!{interchangeable.d} if
they can be swapped in a \gls{solution} without affecting the \gls{program}
semantics, which is the case if the values are all \gls{copy-related.d} and none
is both \gls{define.d}[d] and \gls{use.d}[d] by some \gls{match}.
%
In the above example, \irVar{v}[1] and~\irVar{v}[2] constitute such a chain and
can therefore be swapped for $p_1$ and~$p_2$, giving rise to unwanted symmetric
\glspl{solution} (\refFigure{interchangeable-data-example-alt-solutions}).
%
The intuition here is to forbid \glspl{solution} containing ``cross-over''
connections between the values in a chain and the $\mVar{alt}$~\glspl{variable}.
%
As a precaution, however, we will exclude \glspl{operand} used by
\glspl{phi-match} due to the \gls{definition edge} which may require such
cross-over connections.

If we assume that there exists a partial order $\leq$ for~$\mDataSet$, then we
can remove these symmetries using the \gls!{value-precede-chain constraint},
which requires a sequence of \glspl{variable} to be sorted according to a given
chain of values~\cite{LawLee:2004}.
%
Formally, the \gls{constraint} is defined as follows.
%
\begin{definition}[Value-Precede-Chain Constraint]%
  Let \mbox{$\mVar{x}_1, \ldots, \mVar{x}_k$} be a permutation of
  \glspl{variable}.
  %
  Let also $c$ be a 1-indexed sequence with $n$ elements.
  %
  Then
  %
  \begin{displaymath}
    \mValuePrecChain(c, \mVar{x}_1, \ldots, \mVar{x}_k)
    \equiv
    \bigcap_{1 \leq i < n}
    \mValuePrec(c[i], c[i+1], \mVar{x}[1], \ldots \mVar{x}[k]),
  \end{displaymath}
  %
  where
  %
  \begin{displaymath}
    \mValuePrec(s, t, \mVar{x}_1, \ldots, \mVar{x}_k)
    \equiv
    \mSetBuilder{\langle d_1, \ldots, d_k \rangle}%
                {
                  \forall_{\! i} \: d_i \in \mDomain(\mVar{x}_i),
                  \forall_{\! i} \: d_i = t
                  \mImp \exists_{j} \: j < i \mAnd d_j = s
                }.
  \end{displaymath}
  \labelDefinition{vpc}
\end{definition}
%
For example, \mbox{$\mValuePrecChain(\langle 6, 5, 4 \rangle, \mVar{x}_1 \in
  \mSet{6}, \mVar{x}_2 \in \mSet{1}, \mVar{x}_3 \in \mSet{5}, \mVar{x}_4 \in
  \mSet{4})$} holds because the~4 is preceded by a~5, which in turn is preceded
by a~6, in the permutation of $\mVar{x}$~\glspl{variable}.
%
Likewise, \mbox{$\mValuePrecChain(\langle 5, 4 \rangle, \mVar{x}_1 \in \mSet{5},
  \mVar{x}_2 \in \mSet{1})$} also holds because 4 does not appear among the
$\mVar{x}$~\glspl{variable} (the fact that 5 appears in the permutation does
not matter).
%
However, \mbox{$\mValuePrecChain(\langle 5, 4 \rangle, \mVar{x}_1 \in \mSet{1},
  \mVar{x}_2 \in \mSet{4})$} does not hold because the~4 is not preceded by a~5.

Hence, if $\mInterchDataSet$ denotes the set of chains of
\gls{interchangeable.d} \glspl{datum} and \mbox{$\mOperandSet[\mPhi] \subseteq
  \mOperandSet$} denotes the set of \glspl{operand} used by \glspl{phi-match},
then the \gls{dominance breaking.c} \gls{constraint} described above is modeled
as
%
\begin{equation}
  \begin{array}{c}
    \mValuePrecChain(c, \mVar{alt}[p_1], \ldots, \mVar{alt}[p_k]) \\
    \forall c \in \mInterchDataSet,
    \forall p_1, \ldots, p_k \in \mOperandSet \setminus \mOperandSet[\mPhi]
    \text{ \st }
    p_1 \neq \cdots \neq p_k
    \mAnd
    \forall_{\! i} \: \mDataSet[p_i] \! = c.
  \end{array}
  \labelEquation{dom-cons-interch-data-chains}
\end{equation}

Additional symmetries may appear due to \glspl{null-copy match}.
%
Returning to the previous example, if one of the two \glspl{copy node} need to
be covered using a \gls{copy match} derived from actual copy \gls{instruction},
then we are free to decide which.
%
Intuitively, we want to forbid \glspl{solution} where selected \glspl{null-copy
  match} ``appear to the left'' of a non-\gls{null-copy match}.
%
To this end, we make use of the \gls!{increasing constraint}, which requires a
sequence of \glspl{variable} to be assigned values in a non-strictly increasing
order.
%
Formally, the \gls{constraint} is defined as follows.
%
\begin{definition}[Increasing Constraint]%
  Let \mbox{$\mVar{x}_1, \ldots, \mVar{x}_k$} be a permutation of
  \glspl{variable}.
  %
  Then
  %
  \begin{displaymath}
    \mIncreasing(\mVar{x}_1, \ldots, \mVar{x}_k)
    \equiv
    \mSetBuilder{\langle d_1, \ldots, d_k \rangle}%
                {
                  \forall_{\! i} \: d_i \in \mDomain(\mVar{x}_i),
                  \forall_{\! i < k} \: d_i \leq d_{i+1}
                }.
  \end{displaymath}
  \labelDefinition{increasing}
\end{definition}
%
Let $\mInterchDataSet[\mCopy]$ denote the set of chains of \glspl{datum} that
can only be defined by \glspl{copy match}, \mbox{$\mNullCopyMatchSet \subseteq
  \mMatchSet$} denote the set of \glspl{null-copy match}, and
\mbox{$\mMatchSet[d] \subseteq \mMatchSet$} denote the set of \glspl{match} that
can define a \gls{datum}~$d$.
%
Using these definitions, this \gls{dominance breaking.c} \glspl{constraint} is
modeled as
%
\begin{equation}
  \begin{array}{c}
    \mIncreasing(\mVar{sel}[m_1], \ldots, \mVar{sel}[m_k]) \\
    \forall c \in \mInterchDataSet[\mCopy],
    \forall 1 \leq i < k,
    \exists m_i \in \mMatchSet[c[i]] \cap \mNullCopyMatchSet \hspace{-.8pt}.
  \end{array}
  \labelEquation{dom-cons-null-copy-match-selection}
\end{equation}
%
It is assumed there exists exactly one \gls{null-copy match} to cover each
\gls{copy node}.

Similarly to \glspl{null-copy match}, symmetries can also arise due to
\glspl{kill match}.
%
In the previous example, for example, if only one of the two \glspl{copy node}
are needed, then we are free to decide which.
%
Intuitively, we want to forbid \glspl{solution} where \gls{killed.d}
\glspl{datum} ``appear to the right'' of non-\gls{killed.d} \glspl{datum}, and
again we make use of the \gls{increasing constraint} to model this
\gls{dominance breaking.c} \gls{constraint} as
%
\begin{equation}
  \begin{array}{c}
    \mIncreasing(\mVar{sel}[m_1], \ldots, \mVar{sel}[m_k]) \\
    \forall c \in \mInterchDataSet[\mCopy],
    \forall 1 \leq i < k,
    \exists m_i \in \mMatchSet[c[i]] \cap \mKillMatchSet,
  \end{array}
  \labelEquation{dom-cons-kill-match-selection}
\end{equation}
%
where $\mKillMatchSet$ denotes the set of \glspl{kill match}.
%
It is assumed there exists exactly one \gls{kill match} to cover each \gls{copy
  node}.


\section{Presolving}
\labelSection{st-presolving}

As explained in \refChapter{constraint-programming}, \gls{presolving} is the
process of applying problem-specific algorithms to reduce the number of
\glspl{variable} or to shrink the \gls{variable} \glspl{domain} before
solving.\!%
%
\footnote{%
  In this sense, the bound tightening technique described in
  \refSection{st-cost-bounds} is a form of \gls{presolving}.%
}
%
In this dissertation, \gls{presolving} is used to remove \glspl{match} which can
be safely removed without compromising code quality, which directly translates
to fewer $\mVar{alt}$, $\mVar{sel}$, and $\mVar{uplace}$~\glspl{variable},
smaller $\mVar{dplace}$ and $\mVar{oplace}$~\glspl{domain}, as well as fewer
\glspl{constraint} that need to be managed by the \gls{constraint solver}.


\subsection{Dominated Matches}
\labelSection{st-pre-dom-matches}

If two \glspl{match} are equal in all respects except latency, then the
\gls{match} with longer latency is \gls!{dominate.m}[d] and can safely be
removed from the \gls{match set}.
%
A \gls{match}~$m_1$ is \gls{dominate.m}[d] if there exists another
\gls{match}~$m_2$ such that
%
\begin{itemize}
  \item $m_1$ has greater than or equal cost to $m_2$,
  \item both cover the same \glspl{operation},
  \item both have the same \glspl{entry block} (if any),
  \item both \gls{span.b} the same \glspl{block} (if any),
  \item both have the same \glspl{definition edge} (if any),
  \item $m_1$ has at least as strong \gls{location} requirements on its
    \glspl{datum} as $m_2$ -- that is, $\forall p_1 \in \mUses(m_1) \cup
    \mDefines(m_1), \exists p_2 \in \mUses(m_2) \cup \mDefines(m_2) \text{ \st }
    \mDataSet[p_1] \subseteq \mDataSet[p_2] \mAnd \mStores(m_1, p_1) \subseteq
    \mStores(m_2, p_2)$ -- and
  \item both apply the same auxiliary \glspl{constraint} (if any).
\end{itemize}
%
As a precaution, we assume that \glspl{null match}, \glspl{phi-match}, and
\glspl{match} with \gls{fall-through} conditions can never be
\gls{dominate.m}[d].

The method above can be generalized to letting combinations of \glspl{match} to
be jointly \gls{dominate.m}[d] by another \gls{match}.
%
Intuitively, if the combination of \glspl{match} can be selected, then the
\gls{solution} can always be improved by replacing them with the single
\gls{match}.
%
The idea is to combine the \glspl{match} into a single \gls{match}~$m$, and then
check whether the above conditions for \glsshort{dominate.m}[ance] apply with
the additional check that none of intermediate values of $m$ are used by other
\glspl{match}.
%
\begin{figure}
  \centering%
  \input{figures/solving-techniques/dominated-matches-example}

  \caption[Example of dominated matches]%
          {%
            Example where matches~$m_1$ and $m_2$ are jointly dominated by
            match~$m_3$ and can therefore safely be removed (provided that no
            other match uses value~\irVar{v}[3]).
            %
            The table contains the location restrictions enforced by each match%
          }
  \labelFigure{dominated-matches-example}
\end{figure}
%
An example is shown in \refFigure{dominated-matches-example}.


\subsection{Illegal Matches}

Depending on the \gls{instruction set}, the \gls{match set} may contain
\glspl{match} that will, for one reason or another, never participate in any
\gls{solution}.
%
Such \glspl{match} are said to be \gls!{illegal.m}.

One set of \gls{illegal.m} \glspl{match} are those which would leave some
\gls{operation} uncoverable if selected.
%
\begin{figure}
  \centering%
  \input{figures/solving-techniques/uncovered-operations-example}

  \caption[Example of an illegal match]%
          {%
            Example of an illegal match, where selecting match~$m_1$ would leave
            operation~$o_2$ uncovered%
          }
  \labelFigure{uncovered-operations-example}
\end{figure}
%
In \refFigure{uncovered-operations-example}, for example, selecting
\gls{match}~$m_1$ would leave \gls{operation}~$o_2$ uncovered since it can only
be covered by match~$m_2$, but selection of this \gls{match} is inhibited if
$m_1$ is selected.
%
Hence this set of \gls{illegal.m} \glspl{match} is computed as
%
\begin{equation}
  \mSetBuilder{m}%
              {
                \forall m \in \mMatchSet,
                \forall o_1, o_2 \in \mOpSet
                \text{ \st }
                \mMatchSet[o_1] \subset \mMatchSet[o_2]
                \mAnd
                m \in \mMatchSet[o_2]
              }.
  \labelEquation{illegal-matches-uncovered-ops}
\end{equation}

Likewise, a \gls{match} is \gls{illegal.m} if selecting it would
leave some \gls{datum} un\gls{define.d}[d].
%
With similar reasoning, this set of \gls{illegal.m} \glspl{match} is computed as
%
\begin{equation}
  \mSetBuilder{m}%
              {
                \forall m \in \mMatchSet,
                \forall d_1, d_2 \in \mDataSet
                \text{ \st }
                \mMatchSet[d_1] \subset \mMatchSet[d_2]
                \mAnd
                m \in \mMatchSet[d_2]
              }.
  \labelEquation{illegal-matches-undefined-data}
\end{equation}

If a \gls{kill match}~$m$ \gls{define.d}[s] a \gls{datum}~$d$ and every other
\gls{match} using $d$ has no \glsshort{alternative value}[s] but~$d$, then $m$
is \gls{illegal.m} as $d$ must be \gls{define.d}[d] by a non-\gls{kill match}.
%
This set of \gls{illegal.m} \glspl{match} is computed as
%
\begin{equation}
  \mSetBuilder*{m_1}%
               {%
                 \begin{array}{@{}l@{}}
                   m_1 \in \mKillMatchSet,
                   p_1 \in \mDefines(m_1),
                   d \in \mDataSet[p_1], \\
                   m_2 \in \mKillMatchCompSet,
                   p_2 \in \mUses(m_2) \text{ \st }
                   d \in \mDataSet[p_2] \mImp \mDataSet[p_2] = \mSet{d}
                 \end{array}
               }\!.
  \labelEquation{illegal-matches-kills}
\end{equation}

If a \gls{match}~$m$ is not a \gls{kill match} and \gls{define.d}[s] a
\gls{datum}~$d$ in a \gls{location} that cannot be accessed by any of the
\glspl{match} making \gls{use.d} of $d$, then $m$ can never be selected and is
thus \gls{illegal.m}.
%
This set of \gls{illegal.m} \glspl{match} is computed as
%
\begin{equation}
  \mSetBuilder*{m}%
               {%
                 \begin{array}{@{}l@{}}
                   m \in \mKillMatchCompSet,
                   p \in \mDefines(m),
                   d \in \mDataSet[p] \hspace{-1pt} \text{ \st} \\
                   \mIsExt(m, p)
                   \mAnd
                   \mCupUseLocsOf(d) \neq \mEmptySet
                   \mAnd \mbox{} \\
                   \mStores(m, p) \cap \mCupUseLocsOf(d) = \mEmptySet
                 \end{array}
               }\!,
  \labelEquation{illegal-matches-def-locs}
\end{equation}
%
where
%
\begin{equation}
  \mCupUseLocsOf(d)
  \equiv
  \hspace{-2.5em}
  \bigcup_{\substack{%
                   m \, \in \, \mMatchSet[d] \setminus \mKillMatchSet, \\
                   p \, \in \, \mUses(m)
                   \text{ \st } d \, \in \, \mDataSet[p]
                  }}
    \hspace{-2.5em}
    \mStores(m, p).
  \labelEquation{cup-use-locs-of-function}
\end{equation}
%
Note that if \mbox{$\mCupUseLocsOf(d) = \mEmptySet$} holds then the
\glspl{match} \glsshort{use.d}[ing] \gls{datum}~$d$ have themselves conflicting
\gls{location} requirements, and in such cases we cannot infer whether a
\gls{match} \glsshort{define.d}[ing] $d$ is \gls{illegal.m}.

Similarly, if a \gls{match}~$m$ is not a \gls{kill match} and \gls{use.d}[s] a
\gls{datum}~$d$ from a \gls{location} that cannot be written to by any of the
\glspl{match} \glsshort{define.d}[ing]~$d$, then $m$ can never be selected and
is thus \gls{illegal.m}.
%
This set of \gls{illegal.m} \glspl{match} is computed as
%
\begin{equation}
  \mSetBuilder*{m}%
               {%
                 \begin{array}{@{}l@{}}
                   m \in \mKillMatchCompSet,
                   p \in \mUses(m) \setminus \mDefines(m),
                   d \in \mDataSet[p] \hspace{-1pt} \text{ \st} \\
                   \mCupDefLocsOf(d) \neq \mEmptySet
                   \mAnd
                   \mStores(m, p) \cap \mCupDefLocsOf(d) = \mEmptySet
                 \end{array}
               } \!,
  \labelEquation{illegal-matches-use-locs}
\end{equation}
%
where
%
\begin{equation}
  \mCupDefLocsOf(d)
  \equiv
  \hspace{-2.5em}
  \bigcup_{\substack{%
                   m \, \in \, \mMatchSet[d] \setminus \mKillMatchSet, \\
                   p \, \in \, \mDefines(m)
                   \text{ \st } d \, \in \, \mDataSet[p]
                  }}
    \hspace{-2.5em}
    \mStores(m, p).
  \labelEquation{cup-def-locs-of-function}
\end{equation}


\subsection{Redundant Matches}

In certain circumstances a \gls{match} is redundant, meaning it can be
safely removed without compromising code quality.

One such case is that for each \gls{copy node}~$c$, if there exists a
\gls{null-copy match} to cover $c$, then the \gls{kill match} covering $c$ is
redundant since it is always safe to select the \gls{null-copy match} over the
\gls{kill match}.
%
Consequently, all \glspl{kill match} covering \glspl{copy node} that take a
non-constant value as input -- which cannot be covered using a \gls{null-copy
  match} -- can be removed from the \gls{match set}.
%
This makes sense as the \glspl{kill match} were added to the \gls{match set} as
a consequence of \gls{alternative value}, which was introduced to handle cases
where loaded constants could be reused among \glspl{match}.
%
Hence this set of redundant \glspl{match} is computed as
%
\begin{equation}
  \mSetBuilder{m}%
              {%
                m \in \mKillMatchSet,
                o \in \mCovers(m)
                \text{ \st }
                \mMatchSet[o] \cap \mNullCopyMatchSet \neq \mEmptySet
              }.
  \labelEquation{redun-kills}
\end{equation}

Another case concerns \glspl{match} that cover a \gls{copy node} and are not
\glspl{null match}.
%
For each copy chain \mbox{$\mEdge{v_1}{\mEdge{c}{v_2}}$}, where $c$ is a
\gls{copy node} and $v_1$ and $v_2$ are \glspl{value node}, if every \gls{match}
\glsshort{define.d}[ing] $v_1$ writes the value to a \gls{location} that can be
used by all \glspl{match} \glsshort{use.d}[ing]~$v_2$, then all non-\glspl{null
  match} covering $c$ are redundant since a \gls{null-copy match} can always be
selected.
%
We exclude, however, \glspl{copy node} that take a constant value as input since
such \glspl{node} can never be covered by a \gls{null-copy match}.
%
We also exclude \glspl{copy node} whose \gls{define.d}[d] \gls{datum} is
\gls{use.d}[d] by some \gls{phi-match} since an actual copy may be needed to
satisfy \refEquation{phi-match-locations}.
%
Hence this set of redundant \glspl{match} is computed as
%
\begin{equation}
  \mSetBuilder*{m}%
               {%
                 \begin{array}{@{}l@{}}
                   m \in \mCopyMatchSet \setminus \mNullMatchSet,
                   d_1 \in \mUses(m),
                   d_2 \in \mDefines(m) \\
                   \text{\st }
                   \mDataSet[d_1] \cap \mPhiMatchSet = \mEmptySet
                   \mAnd
                   \mDataSet[d_2] \cap \mPhiMatchSet = \mEmptySet
                   \mAnd
                   d_1 \notin \mConstDataSet \\
                   \mbox{}\hspace{-2pt} \mAnd
                   \mCapUseLocsOf(d_1) \cap \mCapDefLocsOf(d_2) \neq \mEmptySet
                 \end{array}
               }\!,
  \labelEquation{redun-non-null-copy-matches}
\end{equation}
%
where \mbox{$\mCopyMatchSet \subseteq \mMatchSet$} denotes the set of
\glspl{copy match}, \mbox{$\mConstDataSet \subseteq \mDataSet$} denotes the set
of \glspl{datum} representing constant values, and \mbox{$\mCapUseLocsOf(d)
  \subseteq \mLocationSet$} and \mbox{$\mCapDefLocsOf(d) \subseteq
  \mLocationSet$} denote the intersection of all \glspl{location} for all
\gls{match} where a \gls{datum}~$d$ is \gls{use.d}[d] respectively
\gls{define.d}[d].
%
As can be deduced from their name, $\mCapUseLocsOf$ and $\mCapDefLocsOf$ are
defined similarly to $\mCupUseLocsOf$ and $\mCupDefLocsOf$ (see
Eqs.\thinspace\refEquation*{cup-use-locs-of-function}
and~\refEquation*{cup-def-locs-of-function}), with the exception that
\glspl{location} known to violate \refEquation{phi-match-locations} are removed
from these sets.


\subsection{Canonical Locations}
\labelSection{st-canonical-locations}

For most architectures, its \glspl{instruction} read from and write to the same
set of \glspl{register}.
%
This gives rise to many symmetric \glspl{solution} as the exact \gls{location}
assigned to a value often does not matter.
%
We can remove these symmetries by removing \glspl{location} which are considered
symmetric to one another.

The idea is to select a \gls{location} as a representative for each distinct
intersection made by the storage requirements.
%
\begin{figure}
  \centering%
  \input{figures/solving-techniques/canonical-locations-example}

  \caption[Example of canonical locations]%
          {%
            Example of canonical locations for a location set with ten
            registers%
          }
  \labelFigure{canonical-locations-example}
\end{figure}
%
See for example \refFigure{canonical-locations-example}.
%
For sake of discussion, each storage requirment has been labeled with a tag.
%
Given the \gls{location set} and storage requirements shown in the figure, they
give rise to five intersections with respect to the locations:
%
\def\mReg#1{\text{\instrFont r$_{\text{#1}}$}}%
%
\mbox{$\mSet{\mReg{1}, \ldots, \mReg{4}}$} due to tags~1 and~2,
%
\mbox{$\mSet{\mReg{5}}$} due to tag~1,
%
$\mSet{\mReg{6}}$ due to tag~1 and~3,
%
\mbox{$\mSet{\mReg{7}, \mReg{8}}$} due to tags~3 and~4, and
%
$\mSet{\mReg{9}}$ due to tag~4.
%
From each of these intersections we select a representative, and the union of
these representative \glspl{location} constitute the set of \gls!{canonical.l}[
  \glspl{location}].
%
An algorithm for computing this set based on the intuition above is shown in
\refAlgorithm{canonical-locs-algorithm}.
%
\begin{algorithm}[t]
  \DeclFunction{CanonicalizeLocs}{location set $L$, match set~$M$}%
  {%
    $T$ \Assign vector with $\mCard{L}$ elements initialized to $\mEmptySet$\;
    $t$ \Assign $1$\;
    \For(\tcp*[f]{assign tags}){$m \in M$}{%
      \For{$p \in \mUses(m) \cup \mDefines(m)$}{%
        \For{$l \in \mStores(m, p)$}{%
          $T[l]$ \Assign $T[l] \cup \mSet{t}$\;
        }
        $t$ \Assign $t$ $+$ $1$\;
      }
    }
    $G$ \Assign $\mSetBuilder{T[l]}{l \in L}$\tcp*{find all groups of tags}
    $L_{\mathsc{c}}$ \Assign $\mEmptySet$\;
    \For{$g \in G$}{%
      $l_{\mathsc{c}}$ \Assign
      $\mMin(\mSetBuilder{l}{l \in L \text{ \st } T[l] = g})$
      \tcp*{find representative for this group of tags}
      $L_{\mathsc{c}}$ \Assign
      $L_{\mathsc{c}} \cup \mSet{l_{\mathsc{c}}}$\;
    }
    \Return $L_{\mathsc{c}}$\;
  }

  \caption[Algorithm for computing the set of canonical locations]%
          {%
            Computes the canonical locations from a given location set.
            %
            If location restrictions for some data are already enforced by
            the function, then these are also tagged and processed accordingly%
          }
  \labelAlgorithm{canonical-locs-algorithm}
\end{algorithm}

Once computed, we substitute all locations appearing in the storage requirements
with their \gls{canonical.l} representative and then replace the original
\gls{location set} with the \gls{canonical.l} set, thus shrinking the
\glspl{domain} of the $\mVar{loc}$~\glspl{variable}.


\section{Experimental Evaluation}
\labelSection{st-experimental-evaluation}

Excluding the refinement described in \refSection{st-refining-define-before-use
  constraint}, whose naive equivalence cannot be implemented on this
experimental setup and therefore not be evaluated, we now evaluate the impact of
each solving technique introduced in this chapter.

For all experiments, the setup is the same as in
\refSection{cm-alt-values-experimental-evaluation} with two exceptions.
%
First, when filtering we remove all \glspl{function} that have less than less
than \num{50}~\gls{LLVM} \gls{IR} \glspl{instruction} -- anything smaller will
most likely not show the impact of the given solving technique -- and greater
than \num{150}~\glspl{instruction} -- anything larger will lead to unreasonably
long experiment runtimes.
%
This leaves a pool of \num{284}~\glspl{function}, from which
\num{20}~\glspl{function} are sampled using the same method.
%
Second, when solving we apply time limit of \SI{600}{\s} to the \gls{constraint
  solver}.
%
For any given \gls{function}, the last \gls{solution} found is considered
optimal if and only if the \glsshort{constraint solver} has finished its
execution within the time limit.

When using an upper bound for a given \gls{function}, we take the cost for the
\gls{solution} computed by \mbox{\gls{LLVM} 3.8}.


\subsubsection{Objective Function Refinements and Cost Bounding}

We first evaluate the two methods for computing the cost matrix by comparing the
solving times exhibited by two versions of the \gls{constraint model} -- one
based on the \gls{divide-then-multiply method} and another based on
\glspl{multiply-then-divide method} -- for the set of sampled \glspl{function}.
%
Using the same set of \glspl{function}, we then use the superior method to
evaluate the impact of the \gls{objective function} refinement and cost bounding
by comparing the number of \glspl{function} that can be solved optimally by five
versions of the \gls{constraint model}: two based on the naive implementation of
the \gls{objective function} (\refEquation{naive-objective-function}), one with
cost bounds and one without; and three based on the refined implementation
(Eqs.\thinspace\refEquation*{omatch-oplace-ocost-connection}
and~\refEquation*{total-cost}), one without cost bounds, one with only the upper
bound, and one with both lower and upper bound.
%
We also evaluate the impact on code quality by comparing the cost of the best
\gls{solution} found by two versions of the \gls{constraint model} -- one based
on the naive implementation with upper bound and another based on the refined
implementation with upper bound -- for the same set of \glspl{function}.

Since the refined \gls{objective function} enables tighter bounds to be derived
for the \gls{cost variable}, we expect the \glsplshort{constraint model} based
on the refined implementation to find a greater number of optimal
\glspl{solution} than those based on the naive implementation.
%
Moreover, we expect the \glsplshort{constraint model} with an upper cost bound
to perform better than those with no bounds, and those with both cost bounds to
perform better than those with only one or no bounds.
%
No hypothesis is given for the evaluation of the two methods for computing the
cost matrix.

\begin{figure}
  \centering%
  \maxsizebox{\textwidth}{!}{%
    \trimBarchartPlot{%
      \input{\expDir/new-op-cost-fun-vs-old-pre+solving-time-speedup.plot}%
    }%
  }

  \caption[%
            Plot for evaluating the refined objective function's impact on
            solving time%
          ]%
          {%
            Normalized solving times (including the time for presolving) for two
            constraint models implementing the refined objective function, one
            based on the multiply-then-divide method (baseline) and another
            based on the divide-then-multiply method (subject).
            %
            \Glspl{function} marked with \barValueNotOptimal{} cannot be solved
            optimally by either the baseline or the subject within the time
            limit%
          }
  \labelFigure{new-op-cost-fun-vs-old-plot}
\end{figure}

\input{\expDir/new-op-cost-fun-vs-old-pre+solving-time-speedup.stats}

\RefFigure{new-op-cost-fun-vs-old-plot} shows the normalized solving times
(including the time for presolving) for the two \glspl{constraint model}
described above, with the \glsshort{constraint model} based on the
\gls{multiply-then-divide method} serving as \gls{baseline} and the
\glsshort{constraint model} based on the \gls{divide-then-multiply method}
serving as \gls{subject}.
%
\Glspl{function} marked with \barValueNotOptimal{} cannot be solved optimally
within the time limit; all other \glspl{function} are solved to optimality.
%
The solving times range from
\SIMinOf{
  \NewOpCostFunVsOldPrePlusSolvingTimeSpeedupPrePlusSolvingTimeAvgMin,
  \NewOpCostFunVsOldPrePlusSolvingTimeSpeedupBaselinePrePlusSolvingTimeAvgMin
}{\s} to
\SIMaxOf[round-precision=0]{
  \NewOpCostFunVsOldPrePlusSolvingTimeSpeedupPrePlusSolvingTimeAvgMax,
  \NewOpCostFunVsOldPrePlusSolvingTimeSpeedupBaselinePrePlusSolvingTimeAvgMax
}{\s}
with a maximum coefficient of variation of
\numMaxOf{
  \NewOpCostFunVsOldPrePlusSolvingTimeSpeedupPrePlusSolvingTimeCvMax,
  \NewOpCostFunVsOldPrePlusSolvingTimeSpeedupBaselinePrePlusSolvingTimeCvMax
}.
%
Except for three \glspl{function} ({\codeFont alloc\_name\_is\_s}, {\codeFont
  debug\_dump\_byte}, and {\codeFont write\_file\_trai}), the
\gls{divide-then-multiply method} yields significantly lower solving times than
the other method.
%
In three cases ({\codeFont checksum}, {\codeFont gl\_swap4}, and {\codeFont
  jinit\_forward\_d}), the solving time is more than five times shorter.
%
Hence, when implementing the refined \gls{objective function}, the
\glspl{divide-then-multiply method} is a better design choice over the
\gls{multiply-then-divide method}.
%
This observation also underscores the fact that seemingly trivial changes to a
\gls{constraint model} may have considerable impact on solving time.

\begin{figure}
  \renewcommand{\plotPercentageFont}{\large}
  \renewcommand{\plotSecondsFont}{\large}
  \centering%
  \maxsizebox{.6\textwidth}{!}{%
    \trimLinechartPlot{%
      \input{\expDir/obj-fun-refined-vs-naive-opt-proofs-over-time.plot}%
    }%
  }

  \caption[%
            Plot for evaluating the refined objective function's impact on
            finding optimal solutions%
          ]%
          {%
            Percentage of optimal solutions found over time for five constraint
            models implementing the naive and refined objective function, with
            and without bounds%
          }
  \labelFigure{obj-fun-refined-vs-naive-opt-proofs-over-time-plot}
\end{figure}

\input{\expDir/obj-fun-refined-vs-naive-opt-proofs-over-time.stats}

\RefFigure{obj-fun-refined-vs-naive-opt-proofs-over-time-plot} shows the
percentage of optimal \glspl{solution} found over time for the five
\glspl{constraint model} described above.
%
The solving times range from
\SIMinOf{
  \ObjFunRefinedVsNaiveOptProofsOverTimeNaiveNoBoundsSolvingTimeAvgMin,
  \ObjFunRefinedVsNaiveOptProofsOverTimeNaiveWUbSolvingTimeAvgMin,
  \ObjFunRefinedVsNaiveOptProofsOverTimeRefinedNoBoundsSolvingTimeAvgMin,
  \ObjFunRefinedVsNaiveOptProofsOverTimeRefinedWUbSolvingTimeAvgMin,
  \ObjFunRefinedVsNaiveOptProofsOverTimeRefinedWLbUbSolvingTimeAvgMin
}{\s} to
\SIMaxOf[round-precision=0]{
  \ObjFunRefinedVsNaiveOptProofsOverTimeNaiveNoBoundsSolvingTimeAvgMax,
  \ObjFunRefinedVsNaiveOptProofsOverTimeNaiveWUbSolvingTimeAvgMax,
  \ObjFunRefinedVsNaiveOptProofsOverTimeRefinedNoBoundsSolvingTimeAvgMax,
  \ObjFunRefinedVsNaiveOptProofsOverTimeRefinedWUbSolvingTimeAvgMax,
  \ObjFunRefinedVsNaiveOptProofsOverTimeRefinedWLbUbSolvingTimeAvgMax
}{\s}
with a maximum coefficient of variation of
\numMaxOf{
  \ObjFunRefinedVsNaiveOptProofsOverTimeNaiveNoBoundsSolvingTimeCvMax,
  \ObjFunRefinedVsNaiveOptProofsOverTimeNaiveWUbSolvingTimeCvMax,
  \ObjFunRefinedVsNaiveOptProofsOverTimeRefinedNoBoundsSolvingTimeCvMax,
  \ObjFunRefinedVsNaiveOptProofsOverTimeRefinedWUbSolvingTimeCvMax,
  \ObjFunRefinedVsNaiveOptProofsOverTimeRefinedWLbUbSolvingTimeCvMax
}.
%
We see clearly that the \glsplshort{constraint model} based on the refined
\gls{objective function} outperforms those based on the naive implementation.
%
We see also that applying an upper bound has a positive effect for both
\glsplshort{constraint model}.
%
This gain is due to the fact that, for some \glspl{function}, the \gls{solution}
computed by \gls{LLVM} is already optimal with respect to the
\glsshort{constraint model}.
%
Consequently, the \glsshort{constraint solver} need only prove that there exist
no better \gls{solution} instead of exploring the entire \gls{search space}.
%
Hence, the refined \gls{objective function} coupled with an upper cost bound is
crucial for scalability.

Applying a lower bound, however, does not appear to be equally beneficial; in
fact, it even appears to be degrade solving time as the \glsshort{constraint
  model} with both bounds fails to find the optimal \gls{solution} for one
\gls{function} whereas the \glsshort{constraint model} with only the upper bound
manages to find the optimal \gls{solution} for all \glspl{function}.
%
A possible explanation is that the lower bound computed by the relaxed
\gls{constraint model} is too weak to be of any use and instead only interferes
with \gls{Chuffed}'s \gls{lazy clause learning} engine.

\begin{figure}
  \centering%
  \maxsizebox{\textwidth}{!}{%
    \trimBarchartPlot{%
      \input{\expDir/obj-fun-refined-vs-naive-cycles-speedup.plot}%
    }%
  }

  \caption[%
            Plot for evaluating the refined objective function's impact on
            code quality%
          ]%
          {%
            Normalized optimal solution costs for two constraint models, one
            implementing the naive objective function (baseline) and another
            implementing the refined objective function (subject).
            %
            \Glspl{function} marked with \barValueNoBaselineSolution{} are
            those for which the naive objective function fails to produce any
            solution, and \glspl{function} marked with \barValueNoSolution{} are
            those where the solution produced by \gls{LLVM} is already optimal
            \wrt the model.
            %
            \Glspl{function} whose bars are marked with two dots are those
            for which the \gls{subject} fails to find the optimal solution%
          }
  \labelFigure{obj-fun-refined-vs-naive-cycles-speedup-plot}
\end{figure}

\input{\expDir/obj-fun-refined-vs-naive-cycles-speedup.stats}

\RefFigure{obj-fun-refined-vs-naive-cycles-speedup-plot} shows the normalized
\gls{solution} costs for two \glspl{constraint model}: one based on the naive
\gls{objective function} with upper, serving as \gls{baseline}; and another and
based on the refined \gls{objective function} with upper bound, serving as
\gls{subject}.
%
\Glspl{function} marked with \barValueNoBaselineSolution{} are those for which
the \gls{baseline} fails to produce any \gls{solution}, and \glspl{function}
marked with \barValueNoSolution{} are those where the \gls{solution} produced by
\gls{LLVM} is already optimal with respect to the \glsshort{constraint model}.
%
\Glspl{function} whose bars are marked with two dots are those for which the
\gls{subject} fails to find the optimal solution.
%
The costs range from
\numMinOf[round-precision=0]{
  \ObjFunRefinedVsNaiveCyclesSpeedupNaiveWUbCyclesAvgMin,
  \ObjFunRefinedVsNaiveCyclesSpeedupRefinedWUbCyclesAvgMin
}~cycles to
\numMaxOf[round-precision=0]{
  \ObjFunRefinedVsNaiveCyclesSpeedupNaiveWUbCyclesAvgMax,
  \ObjFunRefinedVsNaiveCyclesSpeedupRefinedWUbCyclesAvgMax
}~cycles with a maximum coefficient of variation of
\numMaxOf{
  \ObjFunRefinedVsNaiveCyclesSpeedupNaiveWUbCyclesCvMax,
  \ObjFunRefinedVsNaiveCyclesSpeedupRefinedWUbCyclesCvMax
}.
%
We see clearly that the \glsshort{constraint model} based on the refined
\gls{objective function} yields better code quality than the
\glsshort{constraint model} based on the naive \gls{objective function},
indicating that there is a significant difference between the optimal
\gls{solution} and a \gls{solution} found using inferior solving techniques.
%
Hence, the refined \gls{objective function} coupled with an upper cost bound is
crucial for code quality.


\NewDocumentCommand{\insertSpeedupPlot}{mm}{%
  \maxsizebox{#2\textwidth}{!}{%
    \trimBarchartPlot{\input{#1}}%
  }%
}

\NewDocumentCommand{\insertSolvTechSpeedupPlot}{mm}{%
  \insertSpeedupPlot{%
    \expDir/solv-tech-disable-#1-pre+solving-time-speedup.plot%
  }{#2}
}

\NewDocumentCommand{\mkSolvTechSubfigure}{om}{%
  \subcaptionbox{%
                  \IfValueTF{#1}{#1}{\refEquation{#2}}%
                  \labelFigure{solv-tech-disable-#2}%
                }{%
                  \insertSolvTechSpeedupPlot{#2}{.49}%
                }%
}


\subsubsection{Implied Constraints}

\begin{figure}
  \centering

  \mkSolvTechSubfigure{impl-cons-defs-dominate-defs}%
  \hfill%
  \mkSolvTechSubfigure{impl-cons-defs-in-spanned-blocks}

  \vspace{\betweensubfigures}

  \mkSolvTechSubfigure{impl-cons-identical-entry-blocks}%
  \hfill%
  \mkSolvTechSubfigure{impl-cons-defs-dominate-entry-blocks}

  \vspace{\betweensubfigures}

  \mkSolvTechSubfigure{impl-cons-place-phi-ops-same-as-def-edges}%
  \hfill%
  \mkSolvTechSubfigure{impl-cons-no-span-uses}%

  \vspace{\betweensubfigures}

  \mkSolvTechSubfigure{impl-cons-no-span-defs}%
  \hfill%
  \mkSolvTechSubfigure{impl-cons-no-span-use-defs}

  \vspace{\betweensubfigures}

  \mkSolvTechSubfigure{impl-cons-spanned-input}%
  \hfill%
  \mkSolvTechSubfigure{impl-cons-used-data-must-be-available}

  \mkFigureCaption
  \labelFigure{impl-cons-vs-no-cons-solving-time-plots}
\end{figure}

\let\oldthefigure\thefigure
\renewcommand{\thefigure}{\oldthefigure{} (cont.)}

\begin{figure}
  \ContinuedFloat
  \centering

  \mkSolvTechSubfigure{impl-cons-exterior-data-must-be-available}%
  \hfill%
  \mkSolvTechSubfigure{impl-cons-locs-of-uses}

  \vspace{\betweensubfigures}

  \mkSolvTechSubfigure{impl-cons-locs-of-defs}%
  \hfill%
  \mkSolvTechSubfigure{impl-cons-fix-fall-throughs}

  \mkFigureCaption
\end{figure}

\renewcommand{\thefigure}{\oldthefigure}

\RefFigure{impl-cons-vs-no-cons-solving-time-plots} shows the normalized solving
times (including presolving time) for two \glspl{constraint model}: one based on
the naive \gls{objective function} with upper, serving as \gls{baseline}; and
another and based on the refined \gls{objective function} with upper bound,
serving as \gls{subject}.


\subsubsection{Symmetry and Dominance Breaking Constraints}

\begin{figure}
  \centering

  \mkSolvTechSubfigure{dom-cons-locs-of-states}%
  \hfill%
  \mkSolvTechSubfigure{dom-cons-operands-of-non-selected-matches}

  \vspace{\betweensubfigures}

  \mkSolvTechSubfigure{impl-cons-input-operands-not-taking-min-value}%
  \hfill%
  \mkSolvTechSubfigure{dom-cons-interch-data-chains}

  \vspace{\betweensubfigures}

  \mkSolvTechSubfigure{dom-cons-null-copy-match-selection}%
  \hfill%
  \mkSolvTechSubfigure{dom-cons-kill-match-selection}%

  \caption{TODO}
  \labelFigure{TODO}
\end{figure}


\subsubsection{Presolving}

\begin{figure}
  \centering

  \mkSolvTechSubfigure[Dominated matches]{dom-matches}%
  \hfill%
  \mkSolvTechSubfigure{illegal-matches-uncovered-ops}%

  \vspace{\betweensubfigures}

  \mkSolvTechSubfigure{illegal-matches-undefined-data}%
  \hfill%
  \mkSolvTechSubfigure{illegal-matches-kills}

  \vspace{\betweensubfigures}

  \mkSolvTechSubfigure{illegal-matches-def-locs}%
  \hfill%
  \mkSolvTechSubfigure{illegal-matches-use-locs}

  \vspace{\betweensubfigures}

  \mkSolvTechSubfigure{redun-kills}%
  \hfill%
  \mkSolvTechSubfigure{redun-non-null-copy-matches}

  \vspace{\betweensubfigures}

  \mkSolvTechSubfigure[Canonical locations]{canonical-locs}

  \caption{TODO}
  \labelFigure{TODO}
\end{figure}


\subsubsection{Impact of All Solving Techniques}

\begin{figure}
  \centering%
  \insertSolvTechSpeedupPlot{all}{1}

  \caption{TODO}
  \labelFigure{TODO}
\end{figure}


\section{Summary}
\labelSection{st-summary}

In this chapter, we have introduced a wide range of techniques for solving the
\gls{constraint model} presented in the previous chapter.
%
We have also seen an experimental evaluation of these techniques, demonstrating
that they are crucial for scalability and robustness.
